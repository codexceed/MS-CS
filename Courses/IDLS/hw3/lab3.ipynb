{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcf8246",
   "metadata": {},
   "source": [
    "# Intro to Deep Learning Systems: Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c904ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as transF\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "# from pytorch_cifar import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cdff4d",
   "metadata": {},
   "source": [
    "## Adaptive Learning Rate Methods, CIFAR-10\n",
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "778616a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "batch_size = 512\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=True)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581d5323",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ec9b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(3072, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c45ac",
   "metadata": {},
   "source": [
    "### Q1.2\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce54723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(val_loader, model):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inp, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            input_var = inp.cuda()\n",
    "            target_var = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            _, prediction = torch.max(output.data, 1)\n",
    "            \n",
    "            correct += (prediction == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    return (100 * correct) // total\n",
    "\n",
    "\n",
    "def train_loss(train_loader, model, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    print_freq = 50\n",
    "    l = len(train_loader)\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "        target = target.to(device)\n",
    "        input_var = inputs.to(device)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'.format(epoch, i, l))\n",
    "        \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71226bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using Adagrad optimzer\n",
      "Epoch: [0][0/98]\t\n",
      "Epoch: [0][50/98]\t\n",
      "Epoch: [1][0/98]\t\n",
      "Epoch: [1][50/98]\t\n",
      "Epoch: [2][0/98]\t\n",
      "Epoch: [2][50/98]\t\n",
      "Epoch: [3][0/98]\t\n",
      "Epoch: [3][50/98]\t\n",
      "Epoch: [4][0/98]\t\n",
      "Epoch: [4][50/98]\t\n",
      "Epoch: [5][0/98]\t\n",
      "Epoch: [5][50/98]\t\n",
      "Epoch: [6][0/98]\t\n",
      "Epoch: [6][50/98]\t\n",
      "Epoch: [7][0/98]\t\n",
      "Epoch: [7][50/98]\t\n",
      "Epoch: [8][0/98]\t\n",
      "Epoch: [8][50/98]\t\n",
      "Epoch: [9][0/98]\t\n",
      "Epoch: [9][50/98]\t\n",
      "Epoch: [10][0/98]\t\n",
      "Epoch: [10][50/98]\t\n",
      "Epoch: [11][0/98]\t\n",
      "Epoch: [11][50/98]\t\n",
      "Epoch: [12][0/98]\t\n",
      "Epoch: [12][50/98]\t\n",
      "Epoch: [13][0/98]\t\n",
      "Epoch: [13][50/98]\t\n",
      "Epoch: [14][0/98]\t\n",
      "Epoch: [14][50/98]\t\n",
      "Epoch: [15][0/98]\t\n",
      "Epoch: [15][50/98]\t\n",
      "Epoch: [16][0/98]\t\n",
      "Epoch: [16][50/98]\t\n",
      "Epoch: [17][0/98]\t\n",
      "Epoch: [17][50/98]\t\n",
      "Epoch: [18][0/98]\t\n",
      "Epoch: [18][50/98]\t\n",
      "Epoch: [19][0/98]\t\n",
      "Epoch: [19][50/98]\t\n",
      "Epoch: [20][0/98]\t\n",
      "Epoch: [20][50/98]\t\n",
      "Epoch: [21][0/98]\t\n",
      "Epoch: [21][50/98]\t\n",
      "Epoch: [22][0/98]\t\n",
      "Epoch: [22][50/98]\t\n",
      "Epoch: [23][0/98]\t\n",
      "Epoch: [23][50/98]\t\n",
      "Epoch: [24][0/98]\t\n",
      "Epoch: [24][50/98]\t\n",
      "Epoch: [25][0/98]\t\n",
      "Epoch: [25][50/98]\t\n",
      "Epoch: [26][0/98]\t\n",
      "Epoch: [26][50/98]\t\n",
      "Epoch: [27][0/98]\t\n",
      "Epoch: [27][50/98]\t\n",
      "Epoch: [28][0/98]\t\n",
      "Epoch: [28][50/98]\t\n",
      "Epoch: [29][0/98]\t\n",
      "Epoch: [29][50/98]\t\n",
      "Epoch: [30][0/98]\t\n",
      "Epoch: [30][50/98]\t\n",
      "Epoch: [31][0/98]\t\n",
      "Epoch: [31][50/98]\t\n",
      "Epoch: [32][0/98]\t\n",
      "Epoch: [32][50/98]\t\n",
      "Epoch: [33][0/98]\t\n",
      "Epoch: [33][50/98]\t\n",
      "Epoch: [34][0/98]\t\n",
      "Epoch: [34][50/98]\t\n",
      "Epoch: [35][0/98]\t\n",
      "Epoch: [35][50/98]\t\n",
      "Epoch: [36][0/98]\t\n",
      "Epoch: [36][50/98]\t\n",
      "Epoch: [37][0/98]\t\n",
      "Epoch: [37][50/98]\t\n",
      "Epoch: [38][0/98]\t\n",
      "Epoch: [38][50/98]\t\n",
      "Epoch: [39][0/98]\t\n",
      "Epoch: [39][50/98]\t\n",
      "Epoch: [40][0/98]\t\n",
      "Epoch: [40][50/98]\t\n",
      "Epoch: [41][0/98]\t\n",
      "Epoch: [41][50/98]\t\n",
      "Epoch: [42][0/98]\t\n",
      "Epoch: [42][50/98]\t\n",
      "Epoch: [43][0/98]\t\n",
      "Epoch: [43][50/98]\t\n",
      "Epoch: [44][0/98]\t\n",
      "Epoch: [44][50/98]\t\n",
      "Epoch: [45][0/98]\t\n",
      "Epoch: [45][50/98]\t\n",
      "Epoch: [46][0/98]\t\n",
      "Epoch: [46][50/98]\t\n",
      "Epoch: [47][0/98]\t\n",
      "Epoch: [47][50/98]\t\n",
      "Epoch: [48][0/98]\t\n",
      "Epoch: [48][50/98]\t\n",
      "Epoch: [49][0/98]\t\n",
      "Epoch: [49][50/98]\t\n",
      "Epoch: [50][0/98]\t\n",
      "Epoch: [50][50/98]\t\n",
      "Epoch: [51][0/98]\t\n",
      "Epoch: [51][50/98]\t\n",
      "Epoch: [52][0/98]\t\n",
      "Epoch: [52][50/98]\t\n",
      "Epoch: [53][0/98]\t\n",
      "Epoch: [53][50/98]\t\n",
      "Epoch: [54][0/98]\t\n",
      "Epoch: [54][50/98]\t\n",
      "Epoch: [55][0/98]\t\n",
      "Epoch: [55][50/98]\t\n",
      "Epoch: [56][0/98]\t\n",
      "Epoch: [56][50/98]\t\n",
      "Epoch: [57][0/98]\t\n",
      "Epoch: [57][50/98]\t\n",
      "Epoch: [58][0/98]\t\n",
      "Epoch: [58][50/98]\t\n",
      "Epoch: [59][0/98]\t\n",
      "Epoch: [59][50/98]\t\n",
      "Epoch: [60][0/98]\t\n",
      "Epoch: [60][50/98]\t\n",
      "Epoch: [61][0/98]\t\n",
      "Epoch: [61][50/98]\t\n",
      "Epoch: [62][0/98]\t\n",
      "Epoch: [62][50/98]\t\n",
      "Epoch: [63][0/98]\t\n",
      "Epoch: [63][50/98]\t\n",
      "Epoch: [64][0/98]\t\n",
      "Epoch: [64][50/98]\t\n",
      "Epoch: [65][0/98]\t\n",
      "Epoch: [65][50/98]\t\n",
      "Epoch: [66][0/98]\t\n",
      "Epoch: [66][50/98]\t\n",
      "Epoch: [67][0/98]\t\n",
      "Epoch: [67][50/98]\t\n",
      "Epoch: [68][0/98]\t\n",
      "Epoch: [68][50/98]\t\n",
      "Epoch: [69][0/98]\t\n",
      "Epoch: [69][50/98]\t\n",
      "Epoch: [70][0/98]\t\n",
      "Epoch: [70][50/98]\t\n",
      "Epoch: [71][0/98]\t\n",
      "Epoch: [71][50/98]\t\n",
      "Epoch: [72][0/98]\t\n",
      "Epoch: [72][50/98]\t\n",
      "Epoch: [73][0/98]\t\n",
      "Epoch: [73][50/98]\t\n",
      "Epoch: [74][0/98]\t\n",
      "Epoch: [74][50/98]\t\n",
      "Epoch: [75][0/98]\t\n",
      "Epoch: [75][50/98]\t\n",
      "Epoch: [76][0/98]\t\n",
      "Epoch: [76][50/98]\t\n",
      "Epoch: [77][0/98]\t\n",
      "Epoch: [77][50/98]\t\n",
      "Epoch: [78][0/98]\t\n",
      "Epoch: [78][50/98]\t\n",
      "Epoch: [79][0/98]\t\n",
      "Epoch: [79][50/98]\t\n",
      "Epoch: [80][0/98]\t\n",
      "Epoch: [80][50/98]\t\n",
      "Epoch: [81][0/98]\t\n",
      "Epoch: [81][50/98]\t\n",
      "Epoch: [82][0/98]\t\n",
      "Epoch: [82][50/98]\t\n",
      "Epoch: [83][0/98]\t\n",
      "Epoch: [83][50/98]\t\n",
      "Epoch: [84][0/98]\t\n",
      "Epoch: [84][50/98]\t\n",
      "Epoch: [85][0/98]\t\n",
      "Epoch: [85][50/98]\t\n",
      "Epoch: [86][0/98]\t\n",
      "Epoch: [86][50/98]\t\n",
      "Epoch: [87][0/98]\t\n",
      "Epoch: [87][50/98]\t\n",
      "Epoch: [88][0/98]\t\n",
      "Epoch: [88][50/98]\t\n",
      "Epoch: [89][0/98]\t\n",
      "Epoch: [89][50/98]\t\n",
      "Epoch: [90][0/98]\t\n",
      "Epoch: [90][50/98]\t\n",
      "Epoch: [91][0/98]\t\n",
      "Epoch: [91][50/98]\t\n",
      "Epoch: [92][0/98]\t\n",
      "Epoch: [92][50/98]\t\n",
      "Epoch: [93][0/98]\t\n",
      "Epoch: [93][50/98]\t\n",
      "Epoch: [94][0/98]\t\n",
      "Epoch: [94][50/98]\t\n",
      "Epoch: [95][0/98]\t\n",
      "Epoch: [95][50/98]\t\n",
      "Epoch: [96][0/98]\t\n",
      "Epoch: [96][50/98]\t\n",
      "Epoch: [97][0/98]\t\n",
      "Epoch: [97][50/98]\t\n",
      "Epoch: [98][0/98]\t\n",
      "Epoch: [98][50/98]\t\n",
      "Epoch: [99][0/98]\t\n",
      "Epoch: [99][50/98]\t\n",
      "Epoch: [100][0/98]\t\n",
      "Epoch: [100][50/98]\t\n",
      "Epoch: [101][0/98]\t\n",
      "Epoch: [101][50/98]\t\n",
      "Epoch: [102][0/98]\t\n",
      "Epoch: [102][50/98]\t\n",
      "Epoch: [103][0/98]\t\n",
      "Epoch: [103][50/98]\t\n",
      "Epoch: [104][0/98]\t\n",
      "Epoch: [104][50/98]\t\n",
      "Epoch: [105][0/98]\t\n",
      "Epoch: [105][50/98]\t\n",
      "Epoch: [106][0/98]\t\n",
      "Epoch: [106][50/98]\t\n",
      "Epoch: [107][0/98]\t\n",
      "Epoch: [107][50/98]\t\n",
      "Epoch: [108][0/98]\t\n",
      "Epoch: [108][50/98]\t\n",
      "Epoch: [109][0/98]\t\n",
      "Epoch: [109][50/98]\t\n",
      "Epoch: [110][0/98]\t\n",
      "Epoch: [110][50/98]\t\n",
      "Epoch: [111][0/98]\t\n",
      "Epoch: [111][50/98]\t\n",
      "Epoch: [112][0/98]\t\n",
      "Epoch: [112][50/98]\t\n",
      "Epoch: [113][0/98]\t\n",
      "Epoch: [113][50/98]\t\n",
      "Epoch: [114][0/98]\t\n",
      "Epoch: [114][50/98]\t\n",
      "Epoch: [115][0/98]\t\n",
      "Epoch: [115][50/98]\t\n",
      "Epoch: [116][0/98]\t\n",
      "Epoch: [116][50/98]\t\n",
      "Epoch: [117][0/98]\t\n",
      "Epoch: [117][50/98]\t\n",
      "Epoch: [118][0/98]\t\n",
      "Epoch: [118][50/98]\t\n",
      "Epoch: [119][0/98]\t\n",
      "Epoch: [119][50/98]\t\n",
      "Epoch: [120][0/98]\t\n",
      "Epoch: [120][50/98]\t\n",
      "Epoch: [121][0/98]\t\n",
      "Epoch: [121][50/98]\t\n",
      "Epoch: [122][0/98]\t\n",
      "Epoch: [122][50/98]\t\n",
      "Epoch: [123][0/98]\t\n",
      "Epoch: [123][50/98]\t\n",
      "Epoch: [124][0/98]\t\n",
      "Epoch: [124][50/98]\t\n",
      "Epoch: [125][0/98]\t\n",
      "Epoch: [125][50/98]\t\n",
      "Epoch: [126][0/98]\t\n",
      "Epoch: [126][50/98]\t\n",
      "Epoch: [127][0/98]\t\n",
      "Epoch: [127][50/98]\t\n",
      "Epoch: [128][0/98]\t\n",
      "Epoch: [128][50/98]\t\n",
      "Epoch: [129][0/98]\t\n",
      "Epoch: [129][50/98]\t\n",
      "Epoch: [130][0/98]\t\n",
      "Epoch: [130][50/98]\t\n",
      "Epoch: [131][0/98]\t\n",
      "Epoch: [131][50/98]\t\n",
      "Epoch: [132][0/98]\t\n",
      "Epoch: [132][50/98]\t\n",
      "Epoch: [133][0/98]\t\n",
      "Epoch: [133][50/98]\t\n",
      "Epoch: [134][0/98]\t\n",
      "Epoch: [134][50/98]\t\n",
      "Epoch: [135][0/98]\t\n",
      "Epoch: [135][50/98]\t\n",
      "Epoch: [136][0/98]\t\n",
      "Epoch: [136][50/98]\t\n",
      "Epoch: [137][0/98]\t\n",
      "Epoch: [137][50/98]\t\n",
      "Epoch: [138][0/98]\t\n",
      "Epoch: [138][50/98]\t\n",
      "Epoch: [139][0/98]\t\n",
      "Epoch: [139][50/98]\t\n",
      "Epoch: [140][0/98]\t\n",
      "Epoch: [140][50/98]\t\n",
      "Epoch: [141][0/98]\t\n",
      "Epoch: [141][50/98]\t\n",
      "Epoch: [142][0/98]\t\n",
      "Epoch: [142][50/98]\t\n",
      "Epoch: [143][0/98]\t\n",
      "Epoch: [143][50/98]\t\n",
      "Epoch: [144][0/98]\t\n",
      "Epoch: [144][50/98]\t\n",
      "Epoch: [145][0/98]\t\n",
      "Epoch: [145][50/98]\t\n",
      "Epoch: [146][0/98]\t\n",
      "Epoch: [146][50/98]\t\n",
      "Epoch: [147][0/98]\t\n",
      "Epoch: [147][50/98]\t\n",
      "Epoch: [148][0/98]\t\n",
      "Epoch: [148][50/98]\t\n",
      "Epoch: [149][0/98]\t\n",
      "Epoch: [149][50/98]\t\n",
      "Epoch: [150][0/98]\t\n",
      "Epoch: [150][50/98]\t\n",
      "Epoch: [151][0/98]\t\n",
      "Epoch: [151][50/98]\t\n",
      "Epoch: [152][0/98]\t\n",
      "Epoch: [152][50/98]\t\n",
      "Epoch: [153][0/98]\t\n",
      "Epoch: [153][50/98]\t\n",
      "Epoch: [154][0/98]\t\n",
      "Epoch: [154][50/98]\t\n",
      "Epoch: [155][0/98]\t\n",
      "Epoch: [155][50/98]\t\n",
      "Epoch: [156][0/98]\t\n",
      "Epoch: [156][50/98]\t\n",
      "Epoch: [157][0/98]\t\n",
      "Epoch: [157][50/98]\t\n",
      "Epoch: [158][0/98]\t\n",
      "Epoch: [158][50/98]\t\n",
      "Epoch: [159][0/98]\t\n",
      "Epoch: [159][50/98]\t\n",
      "Epoch: [160][0/98]\t\n",
      "Epoch: [160][50/98]\t\n",
      "Epoch: [161][0/98]\t\n",
      "Epoch: [161][50/98]\t\n",
      "Epoch: [162][0/98]\t\n",
      "Epoch: [162][50/98]\t\n",
      "Epoch: [163][0/98]\t\n",
      "Epoch: [163][50/98]\t\n",
      "Epoch: [164][0/98]\t\n",
      "Epoch: [164][50/98]\t\n",
      "Epoch: [165][0/98]\t\n",
      "Epoch: [165][50/98]\t\n",
      "Epoch: [166][0/98]\t\n",
      "Epoch: [166][50/98]\t\n",
      "Epoch: [167][0/98]\t\n",
      "Epoch: [167][50/98]\t\n",
      "Epoch: [168][0/98]\t\n",
      "Epoch: [168][50/98]\t\n",
      "Epoch: [169][0/98]\t\n",
      "Epoch: [169][50/98]\t\n",
      "Epoch: [170][0/98]\t\n",
      "Epoch: [170][50/98]\t\n",
      "Epoch: [171][0/98]\t\n",
      "Epoch: [171][50/98]\t\n",
      "Epoch: [172][0/98]\t\n",
      "Epoch: [172][50/98]\t\n",
      "Epoch: [173][0/98]\t\n",
      "Epoch: [173][50/98]\t\n",
      "Epoch: [174][0/98]\t\n",
      "Epoch: [174][50/98]\t\n",
      "Epoch: [175][0/98]\t\n",
      "Epoch: [175][50/98]\t\n",
      "Epoch: [176][0/98]\t\n",
      "Epoch: [176][50/98]\t\n",
      "Epoch: [177][0/98]\t\n",
      "Epoch: [177][50/98]\t\n",
      "Epoch: [178][0/98]\t\n",
      "Epoch: [178][50/98]\t\n",
      "Epoch: [179][0/98]\t\n",
      "Epoch: [179][50/98]\t\n",
      "Epoch: [180][0/98]\t\n",
      "Epoch: [180][50/98]\t\n",
      "Epoch: [181][0/98]\t\n",
      "Epoch: [181][50/98]\t\n",
      "Epoch: [182][0/98]\t\n",
      "Epoch: [182][50/98]\t\n",
      "Epoch: [183][0/98]\t\n",
      "Epoch: [183][50/98]\t\n",
      "Epoch: [184][0/98]\t\n",
      "Epoch: [184][50/98]\t\n",
      "Epoch: [185][0/98]\t\n",
      "Epoch: [185][50/98]\t\n",
      "Epoch: [186][0/98]\t\n",
      "Epoch: [186][50/98]\t\n",
      "Epoch: [187][0/98]\t\n",
      "Epoch: [187][50/98]\t\n",
      "Epoch: [188][0/98]\t\n",
      "Epoch: [188][50/98]\t\n",
      "Epoch: [189][0/98]\t\n",
      "Epoch: [189][50/98]\t\n",
      "Epoch: [190][0/98]\t\n",
      "Epoch: [190][50/98]\t\n",
      "Epoch: [191][0/98]\t\n",
      "Epoch: [191][50/98]\t\n",
      "Epoch: [192][0/98]\t\n",
      "Epoch: [192][50/98]\t\n",
      "Epoch: [193][0/98]\t\n",
      "Epoch: [193][50/98]\t\n",
      "Epoch: [194][0/98]\t\n",
      "Epoch: [194][50/98]\t\n",
      "Epoch: [195][0/98]\t\n",
      "Epoch: [195][50/98]\t\n",
      "Epoch: [196][0/98]\t\n",
      "Epoch: [196][50/98]\t\n",
      "Epoch: [197][0/98]\t\n",
      "Epoch: [197][50/98]\t\n",
      "Epoch: [198][0/98]\t\n",
      "Epoch: [198][50/98]\t\n",
      "Epoch: [199][0/98]\t\n",
      "Epoch: [199][50/98]\t\n",
      "Training using RMSprop optimzer\n",
      "Epoch: [0][0/98]\t\n",
      "Epoch: [0][50/98]\t\n",
      "Epoch: [1][0/98]\t\n",
      "Epoch: [1][50/98]\t\n",
      "Epoch: [2][0/98]\t\n",
      "Epoch: [2][50/98]\t\n",
      "Epoch: [3][0/98]\t\n",
      "Epoch: [3][50/98]\t\n",
      "Epoch: [4][0/98]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4][50/98]\t\n",
      "Epoch: [5][0/98]\t\n",
      "Epoch: [5][50/98]\t\n",
      "Epoch: [6][0/98]\t\n",
      "Epoch: [6][50/98]\t\n",
      "Epoch: [7][0/98]\t\n",
      "Epoch: [7][50/98]\t\n",
      "Epoch: [8][0/98]\t\n",
      "Epoch: [8][50/98]\t\n",
      "Epoch: [9][0/98]\t\n",
      "Epoch: [9][50/98]\t\n",
      "Epoch: [10][0/98]\t\n",
      "Epoch: [10][50/98]\t\n",
      "Epoch: [11][0/98]\t\n",
      "Epoch: [11][50/98]\t\n",
      "Epoch: [12][0/98]\t\n",
      "Epoch: [12][50/98]\t\n",
      "Epoch: [13][0/98]\t\n",
      "Epoch: [13][50/98]\t\n",
      "Epoch: [14][0/98]\t\n",
      "Epoch: [14][50/98]\t\n",
      "Epoch: [15][0/98]\t\n",
      "Epoch: [15][50/98]\t\n",
      "Epoch: [16][0/98]\t\n",
      "Epoch: [16][50/98]\t\n",
      "Epoch: [17][0/98]\t\n",
      "Epoch: [17][50/98]\t\n",
      "Epoch: [18][0/98]\t\n",
      "Epoch: [18][50/98]\t\n",
      "Epoch: [19][0/98]\t\n",
      "Epoch: [19][50/98]\t\n",
      "Epoch: [20][0/98]\t\n",
      "Epoch: [20][50/98]\t\n",
      "Epoch: [21][0/98]\t\n",
      "Epoch: [21][50/98]\t\n",
      "Epoch: [22][0/98]\t\n",
      "Epoch: [22][50/98]\t\n",
      "Epoch: [23][0/98]\t\n",
      "Epoch: [23][50/98]\t\n",
      "Epoch: [24][0/98]\t\n",
      "Epoch: [24][50/98]\t\n",
      "Epoch: [25][0/98]\t\n",
      "Epoch: [25][50/98]\t\n",
      "Epoch: [26][0/98]\t\n",
      "Epoch: [26][50/98]\t\n",
      "Epoch: [27][0/98]\t\n",
      "Epoch: [27][50/98]\t\n",
      "Epoch: [28][0/98]\t\n",
      "Epoch: [28][50/98]\t\n",
      "Epoch: [29][0/98]\t\n",
      "Epoch: [29][50/98]\t\n",
      "Epoch: [30][0/98]\t\n",
      "Epoch: [30][50/98]\t\n",
      "Epoch: [31][0/98]\t\n",
      "Epoch: [31][50/98]\t\n",
      "Epoch: [32][0/98]\t\n",
      "Epoch: [32][50/98]\t\n",
      "Epoch: [33][0/98]\t\n",
      "Epoch: [33][50/98]\t\n",
      "Epoch: [34][0/98]\t\n",
      "Epoch: [34][50/98]\t\n",
      "Epoch: [35][0/98]\t\n",
      "Epoch: [35][50/98]\t\n",
      "Epoch: [36][0/98]\t\n",
      "Epoch: [36][50/98]\t\n",
      "Epoch: [37][0/98]\t\n",
      "Epoch: [37][50/98]\t\n",
      "Epoch: [38][0/98]\t\n",
      "Epoch: [38][50/98]\t\n",
      "Epoch: [39][0/98]\t\n",
      "Epoch: [39][50/98]\t\n",
      "Epoch: [40][0/98]\t\n",
      "Epoch: [40][50/98]\t\n",
      "Epoch: [41][0/98]\t\n",
      "Epoch: [41][50/98]\t\n",
      "Epoch: [42][0/98]\t\n",
      "Epoch: [42][50/98]\t\n",
      "Epoch: [43][0/98]\t\n",
      "Epoch: [43][50/98]\t\n",
      "Epoch: [44][0/98]\t\n",
      "Epoch: [44][50/98]\t\n",
      "Epoch: [45][0/98]\t\n",
      "Epoch: [45][50/98]\t\n",
      "Epoch: [46][0/98]\t\n",
      "Epoch: [46][50/98]\t\n",
      "Epoch: [47][0/98]\t\n",
      "Epoch: [47][50/98]\t\n",
      "Epoch: [48][0/98]\t\n",
      "Epoch: [48][50/98]\t\n",
      "Epoch: [49][0/98]\t\n",
      "Epoch: [49][50/98]\t\n",
      "Epoch: [50][0/98]\t\n",
      "Epoch: [50][50/98]\t\n",
      "Epoch: [51][0/98]\t\n",
      "Epoch: [51][50/98]\t\n",
      "Epoch: [52][0/98]\t\n",
      "Epoch: [52][50/98]\t\n",
      "Epoch: [53][0/98]\t\n",
      "Epoch: [53][50/98]\t\n",
      "Epoch: [54][0/98]\t\n",
      "Epoch: [54][50/98]\t\n",
      "Epoch: [55][0/98]\t\n",
      "Epoch: [55][50/98]\t\n",
      "Epoch: [56][0/98]\t\n",
      "Epoch: [56][50/98]\t\n",
      "Epoch: [57][0/98]\t\n",
      "Epoch: [57][50/98]\t\n",
      "Epoch: [58][0/98]\t\n",
      "Epoch: [58][50/98]\t\n",
      "Epoch: [59][0/98]\t\n",
      "Epoch: [59][50/98]\t\n",
      "Epoch: [60][0/98]\t\n",
      "Epoch: [60][50/98]\t\n",
      "Epoch: [61][0/98]\t\n",
      "Epoch: [61][50/98]\t\n",
      "Epoch: [62][0/98]\t\n",
      "Epoch: [62][50/98]\t\n",
      "Epoch: [63][0/98]\t\n",
      "Epoch: [63][50/98]\t\n",
      "Epoch: [64][0/98]\t\n",
      "Epoch: [64][50/98]\t\n",
      "Epoch: [65][0/98]\t\n",
      "Epoch: [65][50/98]\t\n",
      "Epoch: [66][0/98]\t\n",
      "Epoch: [66][50/98]\t\n",
      "Epoch: [67][0/98]\t\n",
      "Epoch: [67][50/98]\t\n",
      "Epoch: [68][0/98]\t\n",
      "Epoch: [68][50/98]\t\n",
      "Epoch: [69][0/98]\t\n",
      "Epoch: [69][50/98]\t\n",
      "Epoch: [70][0/98]\t\n",
      "Epoch: [70][50/98]\t\n",
      "Epoch: [71][0/98]\t\n",
      "Epoch: [71][50/98]\t\n",
      "Epoch: [72][0/98]\t\n",
      "Epoch: [72][50/98]\t\n",
      "Epoch: [73][0/98]\t\n",
      "Epoch: [73][50/98]\t\n",
      "Epoch: [74][0/98]\t\n",
      "Epoch: [74][50/98]\t\n",
      "Epoch: [75][0/98]\t\n",
      "Epoch: [75][50/98]\t\n",
      "Epoch: [76][0/98]\t\n",
      "Epoch: [76][50/98]\t\n",
      "Epoch: [77][0/98]\t\n",
      "Epoch: [77][50/98]\t\n",
      "Epoch: [78][0/98]\t\n",
      "Epoch: [78][50/98]\t\n",
      "Epoch: [79][0/98]\t\n",
      "Epoch: [79][50/98]\t\n",
      "Epoch: [80][0/98]\t\n",
      "Epoch: [80][50/98]\t\n",
      "Epoch: [81][0/98]\t\n",
      "Epoch: [81][50/98]\t\n",
      "Epoch: [82][0/98]\t\n",
      "Epoch: [82][50/98]\t\n",
      "Epoch: [83][0/98]\t\n",
      "Epoch: [83][50/98]\t\n",
      "Epoch: [84][0/98]\t\n",
      "Epoch: [84][50/98]\t\n",
      "Epoch: [85][0/98]\t\n",
      "Epoch: [85][50/98]\t\n",
      "Epoch: [86][0/98]\t\n",
      "Epoch: [86][50/98]\t\n",
      "Epoch: [87][0/98]\t\n",
      "Epoch: [87][50/98]\t\n",
      "Epoch: [88][0/98]\t\n",
      "Epoch: [88][50/98]\t\n",
      "Epoch: [89][0/98]\t\n",
      "Epoch: [89][50/98]\t\n",
      "Epoch: [90][0/98]\t\n",
      "Epoch: [90][50/98]\t\n",
      "Epoch: [91][0/98]\t\n",
      "Epoch: [91][50/98]\t\n",
      "Epoch: [92][0/98]\t\n",
      "Epoch: [92][50/98]\t\n",
      "Epoch: [93][0/98]\t\n",
      "Epoch: [93][50/98]\t\n",
      "Epoch: [94][0/98]\t\n",
      "Epoch: [94][50/98]\t\n",
      "Epoch: [95][0/98]\t\n",
      "Epoch: [95][50/98]\t\n",
      "Epoch: [96][0/98]\t\n",
      "Epoch: [96][50/98]\t\n",
      "Epoch: [97][0/98]\t\n",
      "Epoch: [97][50/98]\t\n",
      "Epoch: [98][0/98]\t\n",
      "Epoch: [98][50/98]\t\n",
      "Epoch: [99][0/98]\t\n",
      "Epoch: [99][50/98]\t\n",
      "Epoch: [100][0/98]\t\n",
      "Epoch: [100][50/98]\t\n",
      "Epoch: [101][0/98]\t\n",
      "Epoch: [101][50/98]\t\n",
      "Epoch: [102][0/98]\t\n",
      "Epoch: [102][50/98]\t\n",
      "Epoch: [103][0/98]\t\n",
      "Epoch: [103][50/98]\t\n",
      "Epoch: [104][0/98]\t\n",
      "Epoch: [104][50/98]\t\n",
      "Epoch: [105][0/98]\t\n",
      "Epoch: [105][50/98]\t\n",
      "Epoch: [106][0/98]\t\n",
      "Epoch: [106][50/98]\t\n",
      "Epoch: [107][0/98]\t\n",
      "Epoch: [107][50/98]\t\n",
      "Epoch: [108][0/98]\t\n",
      "Epoch: [108][50/98]\t\n",
      "Epoch: [109][0/98]\t\n",
      "Epoch: [109][50/98]\t\n",
      "Epoch: [110][0/98]\t\n",
      "Epoch: [110][50/98]\t\n",
      "Epoch: [111][0/98]\t\n",
      "Epoch: [111][50/98]\t\n",
      "Epoch: [112][0/98]\t\n",
      "Epoch: [112][50/98]\t\n",
      "Epoch: [113][0/98]\t\n",
      "Epoch: [113][50/98]\t\n",
      "Epoch: [114][0/98]\t\n",
      "Epoch: [114][50/98]\t\n",
      "Epoch: [115][0/98]\t\n",
      "Epoch: [115][50/98]\t\n",
      "Epoch: [116][0/98]\t\n",
      "Epoch: [116][50/98]\t\n",
      "Epoch: [117][0/98]\t\n",
      "Epoch: [117][50/98]\t\n",
      "Epoch: [118][0/98]\t\n",
      "Epoch: [118][50/98]\t\n",
      "Epoch: [119][0/98]\t\n",
      "Epoch: [119][50/98]\t\n",
      "Epoch: [120][0/98]\t\n",
      "Epoch: [120][50/98]\t\n",
      "Epoch: [121][0/98]\t\n",
      "Epoch: [121][50/98]\t\n",
      "Epoch: [122][0/98]\t\n",
      "Epoch: [122][50/98]\t\n",
      "Epoch: [123][0/98]\t\n",
      "Epoch: [123][50/98]\t\n",
      "Epoch: [124][0/98]\t\n",
      "Epoch: [124][50/98]\t\n",
      "Epoch: [125][0/98]\t\n",
      "Epoch: [125][50/98]\t\n",
      "Epoch: [126][0/98]\t\n",
      "Epoch: [126][50/98]\t\n",
      "Epoch: [127][0/98]\t\n",
      "Epoch: [127][50/98]\t\n",
      "Epoch: [128][0/98]\t\n",
      "Epoch: [128][50/98]\t\n",
      "Epoch: [129][0/98]\t\n",
      "Epoch: [129][50/98]\t\n",
      "Epoch: [130][0/98]\t\n",
      "Epoch: [130][50/98]\t\n",
      "Epoch: [131][0/98]\t\n",
      "Epoch: [131][50/98]\t\n",
      "Epoch: [132][0/98]\t\n",
      "Epoch: [132][50/98]\t\n",
      "Epoch: [133][0/98]\t\n",
      "Epoch: [133][50/98]\t\n",
      "Epoch: [134][0/98]\t\n",
      "Epoch: [134][50/98]\t\n",
      "Epoch: [135][0/98]\t\n",
      "Epoch: [135][50/98]\t\n",
      "Epoch: [136][0/98]\t\n",
      "Epoch: [136][50/98]\t\n",
      "Epoch: [137][0/98]\t\n",
      "Epoch: [137][50/98]\t\n",
      "Epoch: [138][0/98]\t\n",
      "Epoch: [138][50/98]\t\n",
      "Epoch: [139][0/98]\t\n",
      "Epoch: [139][50/98]\t\n",
      "Epoch: [140][0/98]\t\n",
      "Epoch: [140][50/98]\t\n",
      "Epoch: [141][0/98]\t\n",
      "Epoch: [141][50/98]\t\n",
      "Epoch: [142][0/98]\t\n",
      "Epoch: [142][50/98]\t\n",
      "Epoch: [143][0/98]\t\n",
      "Epoch: [143][50/98]\t\n",
      "Epoch: [144][0/98]\t\n",
      "Epoch: [144][50/98]\t\n",
      "Epoch: [145][0/98]\t\n",
      "Epoch: [145][50/98]\t\n",
      "Epoch: [146][0/98]\t\n",
      "Epoch: [146][50/98]\t\n",
      "Epoch: [147][0/98]\t\n",
      "Epoch: [147][50/98]\t\n",
      "Epoch: [148][0/98]\t\n",
      "Epoch: [148][50/98]\t\n",
      "Epoch: [149][0/98]\t\n",
      "Epoch: [149][50/98]\t\n",
      "Epoch: [150][0/98]\t\n",
      "Epoch: [150][50/98]\t\n",
      "Epoch: [151][0/98]\t\n",
      "Epoch: [151][50/98]\t\n",
      "Epoch: [152][0/98]\t\n",
      "Epoch: [152][50/98]\t\n",
      "Epoch: [153][0/98]\t\n",
      "Epoch: [153][50/98]\t\n",
      "Epoch: [154][0/98]\t\n",
      "Epoch: [154][50/98]\t\n",
      "Epoch: [155][0/98]\t\n",
      "Epoch: [155][50/98]\t\n",
      "Epoch: [156][0/98]\t\n",
      "Epoch: [156][50/98]\t\n",
      "Epoch: [157][0/98]\t\n",
      "Epoch: [157][50/98]\t\n",
      "Epoch: [158][0/98]\t\n",
      "Epoch: [158][50/98]\t\n",
      "Epoch: [159][0/98]\t\n",
      "Epoch: [159][50/98]\t\n",
      "Epoch: [160][0/98]\t\n",
      "Epoch: [160][50/98]\t\n",
      "Epoch: [161][0/98]\t\n",
      "Epoch: [161][50/98]\t\n",
      "Epoch: [162][0/98]\t\n",
      "Epoch: [162][50/98]\t\n",
      "Epoch: [163][0/98]\t\n",
      "Epoch: [163][50/98]\t\n",
      "Epoch: [164][0/98]\t\n",
      "Epoch: [164][50/98]\t\n",
      "Epoch: [165][0/98]\t\n",
      "Epoch: [165][50/98]\t\n",
      "Epoch: [166][0/98]\t\n",
      "Epoch: [166][50/98]\t\n",
      "Epoch: [167][0/98]\t\n",
      "Epoch: [167][50/98]\t\n",
      "Epoch: [168][0/98]\t\n",
      "Epoch: [168][50/98]\t\n",
      "Epoch: [169][0/98]\t\n",
      "Epoch: [169][50/98]\t\n",
      "Epoch: [170][0/98]\t\n",
      "Epoch: [170][50/98]\t\n",
      "Epoch: [171][0/98]\t\n",
      "Epoch: [171][50/98]\t\n",
      "Epoch: [172][0/98]\t\n",
      "Epoch: [172][50/98]\t\n",
      "Epoch: [173][0/98]\t\n",
      "Epoch: [173][50/98]\t\n",
      "Epoch: [174][0/98]\t\n",
      "Epoch: [174][50/98]\t\n",
      "Epoch: [175][0/98]\t\n",
      "Epoch: [175][50/98]\t\n",
      "Epoch: [176][0/98]\t\n",
      "Epoch: [176][50/98]\t\n",
      "Epoch: [177][0/98]\t\n",
      "Epoch: [177][50/98]\t\n",
      "Epoch: [178][0/98]\t\n",
      "Epoch: [178][50/98]\t\n",
      "Epoch: [179][0/98]\t\n",
      "Epoch: [179][50/98]\t\n",
      "Epoch: [180][0/98]\t\n",
      "Epoch: [180][50/98]\t\n",
      "Epoch: [181][0/98]\t\n",
      "Epoch: [181][50/98]\t\n",
      "Epoch: [182][0/98]\t\n",
      "Epoch: [182][50/98]\t\n",
      "Epoch: [183][0/98]\t\n",
      "Epoch: [183][50/98]\t\n",
      "Epoch: [184][0/98]\t\n",
      "Epoch: [184][50/98]\t\n",
      "Epoch: [185][0/98]\t\n",
      "Epoch: [185][50/98]\t\n",
      "Epoch: [186][0/98]\t\n",
      "Epoch: [186][50/98]\t\n",
      "Epoch: [187][0/98]\t\n",
      "Epoch: [187][50/98]\t\n",
      "Epoch: [188][0/98]\t\n",
      "Epoch: [188][50/98]\t\n",
      "Epoch: [189][0/98]\t\n",
      "Epoch: [189][50/98]\t\n",
      "Epoch: [190][0/98]\t\n",
      "Epoch: [190][50/98]\t\n",
      "Epoch: [191][0/98]\t\n",
      "Epoch: [191][50/98]\t\n",
      "Epoch: [192][0/98]\t\n",
      "Epoch: [192][50/98]\t\n",
      "Epoch: [193][0/98]\t\n",
      "Epoch: [193][50/98]\t\n",
      "Epoch: [194][0/98]\t\n",
      "Epoch: [194][50/98]\t\n",
      "Epoch: [195][0/98]\t\n",
      "Epoch: [195][50/98]\t\n",
      "Epoch: [196][0/98]\t\n",
      "Epoch: [196][50/98]\t\n",
      "Epoch: [197][0/98]\t\n",
      "Epoch: [197][50/98]\t\n",
      "Epoch: [198][0/98]\t\n",
      "Epoch: [198][50/98]\t\n",
      "Epoch: [199][0/98]\t\n",
      "Epoch: [199][50/98]\t\n",
      "Training using RMSProp+Nesterov optimzer\n",
      "Epoch: [0][0/98]\t\n",
      "Epoch: [0][50/98]\t\n",
      "Epoch: [1][0/98]\t\n",
      "Epoch: [1][50/98]\t\n",
      "Epoch: [2][0/98]\t\n",
      "Epoch: [2][50/98]\t\n",
      "Epoch: [3][0/98]\t\n",
      "Epoch: [3][50/98]\t\n",
      "Epoch: [4][0/98]\t\n",
      "Epoch: [4][50/98]\t\n",
      "Epoch: [5][0/98]\t\n",
      "Epoch: [5][50/98]\t\n",
      "Epoch: [6][0/98]\t\n",
      "Epoch: [6][50/98]\t\n",
      "Epoch: [7][0/98]\t\n",
      "Epoch: [7][50/98]\t\n",
      "Epoch: [8][0/98]\t\n",
      "Epoch: [8][50/98]\t\n",
      "Epoch: [9][0/98]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][50/98]\t\n",
      "Epoch: [10][0/98]\t\n",
      "Epoch: [10][50/98]\t\n",
      "Epoch: [11][0/98]\t\n",
      "Epoch: [11][50/98]\t\n",
      "Epoch: [12][0/98]\t\n",
      "Epoch: [12][50/98]\t\n",
      "Epoch: [13][0/98]\t\n",
      "Epoch: [13][50/98]\t\n",
      "Epoch: [14][0/98]\t\n",
      "Epoch: [14][50/98]\t\n",
      "Epoch: [15][0/98]\t\n",
      "Epoch: [15][50/98]\t\n",
      "Epoch: [16][0/98]\t\n",
      "Epoch: [16][50/98]\t\n",
      "Epoch: [17][0/98]\t\n",
      "Epoch: [17][50/98]\t\n",
      "Epoch: [18][0/98]\t\n",
      "Epoch: [18][50/98]\t\n",
      "Epoch: [19][0/98]\t\n",
      "Epoch: [19][50/98]\t\n",
      "Epoch: [20][0/98]\t\n",
      "Epoch: [20][50/98]\t\n",
      "Epoch: [21][0/98]\t\n",
      "Epoch: [21][50/98]\t\n",
      "Epoch: [22][0/98]\t\n",
      "Epoch: [22][50/98]\t\n",
      "Epoch: [23][0/98]\t\n",
      "Epoch: [23][50/98]\t\n",
      "Epoch: [24][0/98]\t\n",
      "Epoch: [24][50/98]\t\n",
      "Epoch: [25][0/98]\t\n",
      "Epoch: [25][50/98]\t\n",
      "Epoch: [26][0/98]\t\n",
      "Epoch: [26][50/98]\t\n",
      "Epoch: [27][0/98]\t\n",
      "Epoch: [27][50/98]\t\n",
      "Epoch: [28][0/98]\t\n",
      "Epoch: [28][50/98]\t\n",
      "Epoch: [29][0/98]\t\n",
      "Epoch: [29][50/98]\t\n",
      "Epoch: [30][0/98]\t\n",
      "Epoch: [30][50/98]\t\n",
      "Epoch: [31][0/98]\t\n",
      "Epoch: [31][50/98]\t\n",
      "Epoch: [32][0/98]\t\n",
      "Epoch: [32][50/98]\t\n",
      "Epoch: [33][0/98]\t\n",
      "Epoch: [33][50/98]\t\n",
      "Epoch: [34][0/98]\t\n",
      "Epoch: [34][50/98]\t\n",
      "Epoch: [35][0/98]\t\n",
      "Epoch: [35][50/98]\t\n",
      "Epoch: [36][0/98]\t\n",
      "Epoch: [36][50/98]\t\n",
      "Epoch: [37][0/98]\t\n",
      "Epoch: [37][50/98]\t\n",
      "Epoch: [38][0/98]\t\n",
      "Epoch: [38][50/98]\t\n",
      "Epoch: [39][0/98]\t\n",
      "Epoch: [39][50/98]\t\n",
      "Epoch: [40][0/98]\t\n",
      "Epoch: [40][50/98]\t\n",
      "Epoch: [41][0/98]\t\n",
      "Epoch: [41][50/98]\t\n",
      "Epoch: [42][0/98]\t\n",
      "Epoch: [42][50/98]\t\n",
      "Epoch: [43][0/98]\t\n",
      "Epoch: [43][50/98]\t\n",
      "Epoch: [44][0/98]\t\n",
      "Epoch: [44][50/98]\t\n",
      "Epoch: [45][0/98]\t\n",
      "Epoch: [45][50/98]\t\n",
      "Epoch: [46][0/98]\t\n",
      "Epoch: [46][50/98]\t\n",
      "Epoch: [47][0/98]\t\n",
      "Epoch: [47][50/98]\t\n",
      "Epoch: [48][0/98]\t\n",
      "Epoch: [48][50/98]\t\n",
      "Epoch: [49][0/98]\t\n",
      "Epoch: [49][50/98]\t\n",
      "Epoch: [50][0/98]\t\n",
      "Epoch: [50][50/98]\t\n",
      "Epoch: [51][0/98]\t\n",
      "Epoch: [51][50/98]\t\n",
      "Epoch: [52][0/98]\t\n",
      "Epoch: [52][50/98]\t\n",
      "Epoch: [53][0/98]\t\n",
      "Epoch: [53][50/98]\t\n",
      "Epoch: [54][0/98]\t\n",
      "Epoch: [54][50/98]\t\n",
      "Epoch: [55][0/98]\t\n",
      "Epoch: [55][50/98]\t\n",
      "Epoch: [56][0/98]\t\n",
      "Epoch: [56][50/98]\t\n",
      "Epoch: [57][0/98]\t\n",
      "Epoch: [57][50/98]\t\n",
      "Epoch: [58][0/98]\t\n",
      "Epoch: [58][50/98]\t\n",
      "Epoch: [59][0/98]\t\n",
      "Epoch: [59][50/98]\t\n",
      "Epoch: [60][0/98]\t\n",
      "Epoch: [60][50/98]\t\n",
      "Epoch: [61][0/98]\t\n",
      "Epoch: [61][50/98]\t\n",
      "Epoch: [62][0/98]\t\n",
      "Epoch: [62][50/98]\t\n",
      "Epoch: [63][0/98]\t\n",
      "Epoch: [63][50/98]\t\n",
      "Epoch: [64][0/98]\t\n",
      "Epoch: [64][50/98]\t\n",
      "Epoch: [65][0/98]\t\n",
      "Epoch: [65][50/98]\t\n",
      "Epoch: [66][0/98]\t\n",
      "Epoch: [66][50/98]\t\n",
      "Epoch: [67][0/98]\t\n",
      "Epoch: [67][50/98]\t\n",
      "Epoch: [68][0/98]\t\n",
      "Epoch: [68][50/98]\t\n",
      "Epoch: [69][0/98]\t\n",
      "Epoch: [69][50/98]\t\n",
      "Epoch: [70][0/98]\t\n",
      "Epoch: [70][50/98]\t\n",
      "Epoch: [71][0/98]\t\n",
      "Epoch: [71][50/98]\t\n",
      "Epoch: [72][0/98]\t\n",
      "Epoch: [72][50/98]\t\n",
      "Epoch: [73][0/98]\t\n",
      "Epoch: [73][50/98]\t\n",
      "Epoch: [74][0/98]\t\n",
      "Epoch: [74][50/98]\t\n",
      "Epoch: [75][0/98]\t\n",
      "Epoch: [75][50/98]\t\n",
      "Epoch: [76][0/98]\t\n",
      "Epoch: [76][50/98]\t\n",
      "Epoch: [77][0/98]\t\n",
      "Epoch: [77][50/98]\t\n",
      "Epoch: [78][0/98]\t\n",
      "Epoch: [78][50/98]\t\n",
      "Epoch: [79][0/98]\t\n",
      "Epoch: [79][50/98]\t\n",
      "Epoch: [80][0/98]\t\n",
      "Epoch: [80][50/98]\t\n",
      "Epoch: [81][0/98]\t\n",
      "Epoch: [81][50/98]\t\n",
      "Epoch: [82][0/98]\t\n",
      "Epoch: [82][50/98]\t\n",
      "Epoch: [83][0/98]\t\n",
      "Epoch: [83][50/98]\t\n",
      "Epoch: [84][0/98]\t\n",
      "Epoch: [84][50/98]\t\n",
      "Epoch: [85][0/98]\t\n",
      "Epoch: [85][50/98]\t\n",
      "Epoch: [86][0/98]\t\n",
      "Epoch: [86][50/98]\t\n",
      "Epoch: [87][0/98]\t\n",
      "Epoch: [87][50/98]\t\n",
      "Epoch: [88][0/98]\t\n",
      "Epoch: [88][50/98]\t\n",
      "Epoch: [89][0/98]\t\n",
      "Epoch: [89][50/98]\t\n",
      "Epoch: [90][0/98]\t\n",
      "Epoch: [90][50/98]\t\n",
      "Epoch: [91][0/98]\t\n",
      "Epoch: [91][50/98]\t\n",
      "Epoch: [92][0/98]\t\n",
      "Epoch: [92][50/98]\t\n",
      "Epoch: [93][0/98]\t\n",
      "Epoch: [93][50/98]\t\n",
      "Epoch: [94][0/98]\t\n",
      "Epoch: [94][50/98]\t\n",
      "Epoch: [95][0/98]\t\n",
      "Epoch: [95][50/98]\t\n",
      "Epoch: [96][0/98]\t\n",
      "Epoch: [96][50/98]\t\n",
      "Epoch: [97][0/98]\t\n",
      "Epoch: [97][50/98]\t\n",
      "Epoch: [98][0/98]\t\n",
      "Epoch: [98][50/98]\t\n",
      "Epoch: [99][0/98]\t\n",
      "Epoch: [99][50/98]\t\n",
      "Epoch: [100][0/98]\t\n",
      "Epoch: [100][50/98]\t\n",
      "Epoch: [101][0/98]\t\n",
      "Epoch: [101][50/98]\t\n",
      "Epoch: [102][0/98]\t\n",
      "Epoch: [102][50/98]\t\n",
      "Epoch: [103][0/98]\t\n",
      "Epoch: [103][50/98]\t\n",
      "Epoch: [104][0/98]\t\n",
      "Epoch: [104][50/98]\t\n",
      "Epoch: [105][0/98]\t\n",
      "Epoch: [105][50/98]\t\n",
      "Epoch: [106][0/98]\t\n",
      "Epoch: [106][50/98]\t\n",
      "Epoch: [107][0/98]\t\n",
      "Epoch: [107][50/98]\t\n",
      "Epoch: [108][0/98]\t\n",
      "Epoch: [108][50/98]\t\n",
      "Epoch: [109][0/98]\t\n",
      "Epoch: [109][50/98]\t\n",
      "Epoch: [110][0/98]\t\n",
      "Epoch: [110][50/98]\t\n",
      "Epoch: [111][0/98]\t\n",
      "Epoch: [111][50/98]\t\n",
      "Epoch: [112][0/98]\t\n",
      "Epoch: [112][50/98]\t\n",
      "Epoch: [113][0/98]\t\n",
      "Epoch: [113][50/98]\t\n",
      "Epoch: [114][0/98]\t\n",
      "Epoch: [114][50/98]\t\n",
      "Epoch: [115][0/98]\t\n",
      "Epoch: [115][50/98]\t\n",
      "Epoch: [116][0/98]\t\n",
      "Epoch: [116][50/98]\t\n",
      "Epoch: [117][0/98]\t\n",
      "Epoch: [117][50/98]\t\n",
      "Epoch: [118][0/98]\t\n",
      "Epoch: [118][50/98]\t\n",
      "Epoch: [119][0/98]\t\n",
      "Epoch: [119][50/98]\t\n",
      "Epoch: [120][0/98]\t\n",
      "Epoch: [120][50/98]\t\n",
      "Epoch: [121][0/98]\t\n",
      "Epoch: [121][50/98]\t\n",
      "Epoch: [122][0/98]\t\n",
      "Epoch: [122][50/98]\t\n",
      "Epoch: [123][0/98]\t\n",
      "Epoch: [123][50/98]\t\n",
      "Epoch: [124][0/98]\t\n",
      "Epoch: [124][50/98]\t\n",
      "Epoch: [125][0/98]\t\n",
      "Epoch: [125][50/98]\t\n",
      "Epoch: [126][0/98]\t\n",
      "Epoch: [126][50/98]\t\n",
      "Epoch: [127][0/98]\t\n",
      "Epoch: [127][50/98]\t\n",
      "Epoch: [128][0/98]\t\n",
      "Epoch: [128][50/98]\t\n",
      "Epoch: [129][0/98]\t\n",
      "Epoch: [129][50/98]\t\n",
      "Epoch: [130][0/98]\t\n",
      "Epoch: [130][50/98]\t\n",
      "Epoch: [131][0/98]\t\n",
      "Epoch: [131][50/98]\t\n",
      "Epoch: [132][0/98]\t\n",
      "Epoch: [132][50/98]\t\n",
      "Epoch: [133][0/98]\t\n",
      "Epoch: [133][50/98]\t\n",
      "Epoch: [134][0/98]\t\n",
      "Epoch: [134][50/98]\t\n",
      "Epoch: [135][0/98]\t\n",
      "Epoch: [135][50/98]\t\n",
      "Epoch: [136][0/98]\t\n",
      "Epoch: [136][50/98]\t\n",
      "Epoch: [137][0/98]\t\n",
      "Epoch: [137][50/98]\t\n",
      "Epoch: [138][0/98]\t\n",
      "Epoch: [138][50/98]\t\n",
      "Epoch: [139][0/98]\t\n",
      "Epoch: [139][50/98]\t\n",
      "Epoch: [140][0/98]\t\n",
      "Epoch: [140][50/98]\t\n",
      "Epoch: [141][0/98]\t\n",
      "Epoch: [141][50/98]\t\n",
      "Epoch: [142][0/98]\t\n",
      "Epoch: [142][50/98]\t\n",
      "Epoch: [143][0/98]\t\n",
      "Epoch: [143][50/98]\t\n",
      "Epoch: [144][0/98]\t\n",
      "Epoch: [144][50/98]\t\n",
      "Epoch: [145][0/98]\t\n",
      "Epoch: [145][50/98]\t\n",
      "Epoch: [146][0/98]\t\n",
      "Epoch: [146][50/98]\t\n",
      "Epoch: [147][0/98]\t\n",
      "Epoch: [147][50/98]\t\n",
      "Epoch: [148][0/98]\t\n",
      "Epoch: [148][50/98]\t\n",
      "Epoch: [149][0/98]\t\n",
      "Epoch: [149][50/98]\t\n",
      "Epoch: [150][0/98]\t\n",
      "Epoch: [150][50/98]\t\n",
      "Epoch: [151][0/98]\t\n",
      "Epoch: [151][50/98]\t\n",
      "Epoch: [152][0/98]\t\n",
      "Epoch: [152][50/98]\t\n",
      "Epoch: [153][0/98]\t\n",
      "Epoch: [153][50/98]\t\n",
      "Epoch: [154][0/98]\t\n",
      "Epoch: [154][50/98]\t\n",
      "Epoch: [155][0/98]\t\n",
      "Epoch: [155][50/98]\t\n",
      "Epoch: [156][0/98]\t\n",
      "Epoch: [156][50/98]\t\n",
      "Epoch: [157][0/98]\t\n",
      "Epoch: [157][50/98]\t\n",
      "Epoch: [158][0/98]\t\n",
      "Epoch: [158][50/98]\t\n",
      "Epoch: [159][0/98]\t\n",
      "Epoch: [159][50/98]\t\n",
      "Epoch: [160][0/98]\t\n",
      "Epoch: [160][50/98]\t\n",
      "Epoch: [161][0/98]\t\n",
      "Epoch: [161][50/98]\t\n",
      "Epoch: [162][0/98]\t\n",
      "Epoch: [162][50/98]\t\n",
      "Epoch: [163][0/98]\t\n",
      "Epoch: [163][50/98]\t\n",
      "Epoch: [164][0/98]\t\n",
      "Epoch: [164][50/98]\t\n",
      "Epoch: [165][0/98]\t\n",
      "Epoch: [165][50/98]\t\n",
      "Epoch: [166][0/98]\t\n",
      "Epoch: [166][50/98]\t\n",
      "Epoch: [167][0/98]\t\n",
      "Epoch: [167][50/98]\t\n",
      "Epoch: [168][0/98]\t\n",
      "Epoch: [168][50/98]\t\n",
      "Epoch: [169][0/98]\t\n",
      "Epoch: [169][50/98]\t\n",
      "Epoch: [170][0/98]\t\n",
      "Epoch: [170][50/98]\t\n",
      "Epoch: [171][0/98]\t\n",
      "Epoch: [171][50/98]\t\n",
      "Epoch: [172][0/98]\t\n",
      "Epoch: [172][50/98]\t\n",
      "Epoch: [173][0/98]\t\n",
      "Epoch: [173][50/98]\t\n",
      "Epoch: [174][0/98]\t\n",
      "Epoch: [174][50/98]\t\n",
      "Epoch: [175][0/98]\t\n",
      "Epoch: [175][50/98]\t\n",
      "Epoch: [176][0/98]\t\n",
      "Epoch: [176][50/98]\t\n",
      "Epoch: [177][0/98]\t\n",
      "Epoch: [177][50/98]\t\n",
      "Epoch: [178][0/98]\t\n",
      "Epoch: [178][50/98]\t\n",
      "Epoch: [179][0/98]\t\n",
      "Epoch: [179][50/98]\t\n",
      "Epoch: [180][0/98]\t\n",
      "Epoch: [180][50/98]\t\n",
      "Epoch: [181][0/98]\t\n",
      "Epoch: [181][50/98]\t\n",
      "Epoch: [182][0/98]\t\n",
      "Epoch: [182][50/98]\t\n",
      "Epoch: [183][0/98]\t\n",
      "Epoch: [183][50/98]\t\n",
      "Epoch: [184][0/98]\t\n",
      "Epoch: [184][50/98]\t\n",
      "Epoch: [185][0/98]\t\n",
      "Epoch: [185][50/98]\t\n",
      "Epoch: [186][0/98]\t\n",
      "Epoch: [186][50/98]\t\n",
      "Epoch: [187][0/98]\t\n",
      "Epoch: [187][50/98]\t\n",
      "Epoch: [188][0/98]\t\n",
      "Epoch: [188][50/98]\t\n",
      "Epoch: [189][0/98]\t\n",
      "Epoch: [189][50/98]\t\n",
      "Epoch: [190][0/98]\t\n",
      "Epoch: [190][50/98]\t\n",
      "Epoch: [191][0/98]\t\n",
      "Epoch: [191][50/98]\t\n",
      "Epoch: [192][0/98]\t\n",
      "Epoch: [192][50/98]\t\n",
      "Epoch: [193][0/98]\t\n",
      "Epoch: [193][50/98]\t\n",
      "Epoch: [194][0/98]\t\n",
      "Epoch: [194][50/98]\t\n",
      "Epoch: [195][0/98]\t\n",
      "Epoch: [195][50/98]\t\n",
      "Epoch: [196][0/98]\t\n",
      "Epoch: [196][50/98]\t\n",
      "Epoch: [197][0/98]\t\n",
      "Epoch: [197][50/98]\t\n",
      "Epoch: [198][0/98]\t\n",
      "Epoch: [198][50/98]\t\n",
      "Epoch: [199][0/98]\t\n",
      "Epoch: [199][50/98]\t\n",
      "Training using Adadelta optimzer\n",
      "Epoch: [0][0/98]\t\n",
      "Epoch: [0][50/98]\t\n",
      "Epoch: [1][0/98]\t\n",
      "Epoch: [1][50/98]\t\n",
      "Epoch: [2][0/98]\t\n",
      "Epoch: [2][50/98]\t\n",
      "Epoch: [3][0/98]\t\n",
      "Epoch: [3][50/98]\t\n",
      "Epoch: [4][0/98]\t\n",
      "Epoch: [4][50/98]\t\n",
      "Epoch: [5][0/98]\t\n",
      "Epoch: [5][50/98]\t\n",
      "Epoch: [6][0/98]\t\n",
      "Epoch: [6][50/98]\t\n",
      "Epoch: [7][0/98]\t\n",
      "Epoch: [7][50/98]\t\n",
      "Epoch: [8][0/98]\t\n",
      "Epoch: [8][50/98]\t\n",
      "Epoch: [9][0/98]\t\n",
      "Epoch: [9][50/98]\t\n",
      "Epoch: [10][0/98]\t\n",
      "Epoch: [10][50/98]\t\n",
      "Epoch: [11][0/98]\t\n",
      "Epoch: [11][50/98]\t\n",
      "Epoch: [12][0/98]\t\n",
      "Epoch: [12][50/98]\t\n",
      "Epoch: [13][0/98]\t\n",
      "Epoch: [13][50/98]\t\n",
      "Epoch: [14][0/98]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [14][50/98]\t\n",
      "Epoch: [15][0/98]\t\n",
      "Epoch: [15][50/98]\t\n",
      "Epoch: [16][0/98]\t\n",
      "Epoch: [16][50/98]\t\n",
      "Epoch: [17][0/98]\t\n",
      "Epoch: [17][50/98]\t\n",
      "Epoch: [18][0/98]\t\n",
      "Epoch: [18][50/98]\t\n",
      "Epoch: [19][0/98]\t\n",
      "Epoch: [19][50/98]\t\n",
      "Epoch: [20][0/98]\t\n",
      "Epoch: [20][50/98]\t\n",
      "Epoch: [21][0/98]\t\n",
      "Epoch: [21][50/98]\t\n",
      "Epoch: [22][0/98]\t\n",
      "Epoch: [22][50/98]\t\n",
      "Epoch: [23][0/98]\t\n",
      "Epoch: [23][50/98]\t\n",
      "Epoch: [24][0/98]\t\n",
      "Epoch: [24][50/98]\t\n",
      "Epoch: [25][0/98]\t\n",
      "Epoch: [25][50/98]\t\n",
      "Epoch: [26][0/98]\t\n",
      "Epoch: [26][50/98]\t\n",
      "Epoch: [27][0/98]\t\n",
      "Epoch: [27][50/98]\t\n",
      "Epoch: [28][0/98]\t\n",
      "Epoch: [28][50/98]\t\n",
      "Epoch: [29][0/98]\t\n",
      "Epoch: [29][50/98]\t\n",
      "Epoch: [30][0/98]\t\n",
      "Epoch: [30][50/98]\t\n",
      "Epoch: [31][0/98]\t\n",
      "Epoch: [31][50/98]\t\n",
      "Epoch: [32][0/98]\t\n",
      "Epoch: [32][50/98]\t\n",
      "Epoch: [33][0/98]\t\n",
      "Epoch: [33][50/98]\t\n",
      "Epoch: [34][0/98]\t\n",
      "Epoch: [34][50/98]\t\n",
      "Epoch: [35][0/98]\t\n",
      "Epoch: [35][50/98]\t\n",
      "Epoch: [36][0/98]\t\n",
      "Epoch: [36][50/98]\t\n",
      "Epoch: [37][0/98]\t\n",
      "Epoch: [37][50/98]\t\n",
      "Epoch: [38][0/98]\t\n",
      "Epoch: [38][50/98]\t\n",
      "Epoch: [39][0/98]\t\n",
      "Epoch: [39][50/98]\t\n",
      "Epoch: [40][0/98]\t\n",
      "Epoch: [40][50/98]\t\n",
      "Epoch: [41][0/98]\t\n",
      "Epoch: [41][50/98]\t\n",
      "Epoch: [42][0/98]\t\n",
      "Epoch: [42][50/98]\t\n",
      "Epoch: [43][0/98]\t\n",
      "Epoch: [43][50/98]\t\n",
      "Epoch: [44][0/98]\t\n",
      "Epoch: [44][50/98]\t\n",
      "Epoch: [45][0/98]\t\n",
      "Epoch: [45][50/98]\t\n",
      "Epoch: [46][0/98]\t\n",
      "Epoch: [46][50/98]\t\n",
      "Epoch: [47][0/98]\t\n",
      "Epoch: [47][50/98]\t\n",
      "Epoch: [48][0/98]\t\n",
      "Epoch: [48][50/98]\t\n",
      "Epoch: [49][0/98]\t\n",
      "Epoch: [49][50/98]\t\n",
      "Epoch: [50][0/98]\t\n",
      "Epoch: [50][50/98]\t\n",
      "Epoch: [51][0/98]\t\n",
      "Epoch: [51][50/98]\t\n",
      "Epoch: [52][0/98]\t\n",
      "Epoch: [52][50/98]\t\n",
      "Epoch: [53][0/98]\t\n",
      "Epoch: [53][50/98]\t\n",
      "Epoch: [54][0/98]\t\n",
      "Epoch: [54][50/98]\t\n",
      "Epoch: [55][0/98]\t\n",
      "Epoch: [55][50/98]\t\n",
      "Epoch: [56][0/98]\t\n",
      "Epoch: [56][50/98]\t\n",
      "Epoch: [57][0/98]\t\n",
      "Epoch: [57][50/98]\t\n",
      "Epoch: [58][0/98]\t\n",
      "Epoch: [58][50/98]\t\n",
      "Epoch: [59][0/98]\t\n",
      "Epoch: [59][50/98]\t\n",
      "Epoch: [60][0/98]\t\n",
      "Epoch: [60][50/98]\t\n",
      "Epoch: [61][0/98]\t\n",
      "Epoch: [61][50/98]\t\n",
      "Epoch: [62][0/98]\t\n",
      "Epoch: [62][50/98]\t\n",
      "Epoch: [63][0/98]\t\n",
      "Epoch: [63][50/98]\t\n",
      "Epoch: [64][0/98]\t\n",
      "Epoch: [64][50/98]\t\n",
      "Epoch: [65][0/98]\t\n",
      "Epoch: [65][50/98]\t\n",
      "Epoch: [66][0/98]\t\n",
      "Epoch: [66][50/98]\t\n",
      "Epoch: [67][0/98]\t\n",
      "Epoch: [67][50/98]\t\n",
      "Epoch: [68][0/98]\t\n",
      "Epoch: [68][50/98]\t\n",
      "Epoch: [69][0/98]\t\n",
      "Epoch: [69][50/98]\t\n",
      "Epoch: [70][0/98]\t\n",
      "Epoch: [70][50/98]\t\n",
      "Epoch: [71][0/98]\t\n",
      "Epoch: [71][50/98]\t\n",
      "Epoch: [72][0/98]\t\n",
      "Epoch: [72][50/98]\t\n",
      "Epoch: [73][0/98]\t\n",
      "Epoch: [73][50/98]\t\n",
      "Epoch: [74][0/98]\t\n",
      "Epoch: [74][50/98]\t\n",
      "Epoch: [75][0/98]\t\n",
      "Epoch: [75][50/98]\t\n",
      "Epoch: [76][0/98]\t\n",
      "Epoch: [76][50/98]\t\n",
      "Epoch: [77][0/98]\t\n",
      "Epoch: [77][50/98]\t\n",
      "Epoch: [78][0/98]\t\n",
      "Epoch: [78][50/98]\t\n",
      "Epoch: [79][0/98]\t\n",
      "Epoch: [79][50/98]\t\n",
      "Epoch: [80][0/98]\t\n",
      "Epoch: [80][50/98]\t\n",
      "Epoch: [81][0/98]\t\n",
      "Epoch: [81][50/98]\t\n",
      "Epoch: [82][0/98]\t\n",
      "Epoch: [82][50/98]\t\n",
      "Epoch: [83][0/98]\t\n",
      "Epoch: [83][50/98]\t\n",
      "Epoch: [84][0/98]\t\n",
      "Epoch: [84][50/98]\t\n",
      "Epoch: [85][0/98]\t\n",
      "Epoch: [85][50/98]\t\n",
      "Epoch: [86][0/98]\t\n",
      "Epoch: [86][50/98]\t\n",
      "Epoch: [87][0/98]\t\n",
      "Epoch: [87][50/98]\t\n",
      "Epoch: [88][0/98]\t\n",
      "Epoch: [88][50/98]\t\n",
      "Epoch: [89][0/98]\t\n",
      "Epoch: [89][50/98]\t\n",
      "Epoch: [90][0/98]\t\n",
      "Epoch: [90][50/98]\t\n",
      "Epoch: [91][0/98]\t\n",
      "Epoch: [91][50/98]\t\n",
      "Epoch: [92][0/98]\t\n",
      "Epoch: [92][50/98]\t\n",
      "Epoch: [93][0/98]\t\n",
      "Epoch: [93][50/98]\t\n",
      "Epoch: [94][0/98]\t\n",
      "Epoch: [94][50/98]\t\n",
      "Epoch: [95][0/98]\t\n",
      "Epoch: [95][50/98]\t\n",
      "Epoch: [96][0/98]\t\n",
      "Epoch: [96][50/98]\t\n",
      "Epoch: [97][0/98]\t\n",
      "Epoch: [97][50/98]\t\n",
      "Epoch: [98][0/98]\t\n",
      "Epoch: [98][50/98]\t\n",
      "Epoch: [99][0/98]\t\n",
      "Epoch: [99][50/98]\t\n",
      "Epoch: [100][0/98]\t\n",
      "Epoch: [100][50/98]\t\n",
      "Epoch: [101][0/98]\t\n",
      "Epoch: [101][50/98]\t\n",
      "Epoch: [102][0/98]\t\n",
      "Epoch: [102][50/98]\t\n",
      "Epoch: [103][0/98]\t\n",
      "Epoch: [103][50/98]\t\n",
      "Epoch: [104][0/98]\t\n",
      "Epoch: [104][50/98]\t\n",
      "Epoch: [105][0/98]\t\n",
      "Epoch: [105][50/98]\t\n",
      "Epoch: [106][0/98]\t\n",
      "Epoch: [106][50/98]\t\n",
      "Epoch: [107][0/98]\t\n",
      "Epoch: [107][50/98]\t\n",
      "Epoch: [108][0/98]\t\n",
      "Epoch: [108][50/98]\t\n",
      "Epoch: [109][0/98]\t\n",
      "Epoch: [109][50/98]\t\n",
      "Epoch: [110][0/98]\t\n",
      "Epoch: [110][50/98]\t\n",
      "Epoch: [111][0/98]\t\n",
      "Epoch: [111][50/98]\t\n",
      "Epoch: [112][0/98]\t\n",
      "Epoch: [112][50/98]\t\n",
      "Epoch: [113][0/98]\t\n",
      "Epoch: [113][50/98]\t\n",
      "Epoch: [114][0/98]\t\n",
      "Epoch: [114][50/98]\t\n",
      "Epoch: [115][0/98]\t\n",
      "Epoch: [115][50/98]\t\n",
      "Epoch: [116][0/98]\t\n",
      "Epoch: [116][50/98]\t\n",
      "Epoch: [117][0/98]\t\n",
      "Epoch: [117][50/98]\t\n",
      "Epoch: [118][0/98]\t\n",
      "Epoch: [118][50/98]\t\n",
      "Epoch: [119][0/98]\t\n",
      "Epoch: [119][50/98]\t\n",
      "Epoch: [120][0/98]\t\n",
      "Epoch: [120][50/98]\t\n",
      "Epoch: [121][0/98]\t\n",
      "Epoch: [121][50/98]\t\n",
      "Epoch: [122][0/98]\t\n",
      "Epoch: [122][50/98]\t\n",
      "Epoch: [123][0/98]\t\n",
      "Epoch: [123][50/98]\t\n",
      "Epoch: [124][0/98]\t\n",
      "Epoch: [124][50/98]\t\n",
      "Epoch: [125][0/98]\t\n",
      "Epoch: [125][50/98]\t\n",
      "Epoch: [126][0/98]\t\n",
      "Epoch: [126][50/98]\t\n",
      "Epoch: [127][0/98]\t\n",
      "Epoch: [127][50/98]\t\n",
      "Epoch: [128][0/98]\t\n",
      "Epoch: [128][50/98]\t\n",
      "Epoch: [129][0/98]\t\n",
      "Epoch: [129][50/98]\t\n",
      "Epoch: [130][0/98]\t\n",
      "Epoch: [130][50/98]\t\n",
      "Epoch: [131][0/98]\t\n",
      "Epoch: [131][50/98]\t\n",
      "Epoch: [132][0/98]\t\n",
      "Epoch: [132][50/98]\t\n",
      "Epoch: [133][0/98]\t\n",
      "Epoch: [133][50/98]\t\n",
      "Epoch: [134][0/98]\t\n",
      "Epoch: [134][50/98]\t\n",
      "Epoch: [135][0/98]\t\n",
      "Epoch: [135][50/98]\t\n",
      "Epoch: [136][0/98]\t\n",
      "Epoch: [136][50/98]\t\n",
      "Epoch: [137][0/98]\t\n",
      "Epoch: [137][50/98]\t\n",
      "Epoch: [138][0/98]\t\n",
      "Epoch: [138][50/98]\t\n",
      "Epoch: [139][0/98]\t\n",
      "Epoch: [139][50/98]\t\n",
      "Epoch: [140][0/98]\t\n",
      "Epoch: [140][50/98]\t\n",
      "Epoch: [141][0/98]\t\n",
      "Epoch: [141][50/98]\t\n",
      "Epoch: [142][0/98]\t\n",
      "Epoch: [142][50/98]\t\n",
      "Epoch: [143][0/98]\t\n",
      "Epoch: [143][50/98]\t\n",
      "Epoch: [144][0/98]\t\n",
      "Epoch: [144][50/98]\t\n",
      "Epoch: [145][0/98]\t\n",
      "Epoch: [145][50/98]\t\n",
      "Epoch: [146][0/98]\t\n",
      "Epoch: [146][50/98]\t\n",
      "Epoch: [147][0/98]\t\n",
      "Epoch: [147][50/98]\t\n",
      "Epoch: [148][0/98]\t\n",
      "Epoch: [148][50/98]\t\n",
      "Epoch: [149][0/98]\t\n",
      "Epoch: [149][50/98]\t\n",
      "Epoch: [150][0/98]\t\n",
      "Epoch: [150][50/98]\t\n",
      "Epoch: [151][0/98]\t\n",
      "Epoch: [151][50/98]\t\n",
      "Epoch: [152][0/98]\t\n",
      "Epoch: [152][50/98]\t\n",
      "Epoch: [153][0/98]\t\n",
      "Epoch: [153][50/98]\t\n",
      "Epoch: [154][0/98]\t\n",
      "Epoch: [154][50/98]\t\n",
      "Epoch: [155][0/98]\t\n",
      "Epoch: [155][50/98]\t\n",
      "Epoch: [156][0/98]\t\n",
      "Epoch: [156][50/98]\t\n",
      "Epoch: [157][0/98]\t\n",
      "Epoch: [157][50/98]\t\n",
      "Epoch: [158][0/98]\t\n",
      "Epoch: [158][50/98]\t\n",
      "Epoch: [159][0/98]\t\n",
      "Epoch: [159][50/98]\t\n",
      "Epoch: [160][0/98]\t\n",
      "Epoch: [160][50/98]\t\n",
      "Epoch: [161][0/98]\t\n",
      "Epoch: [161][50/98]\t\n",
      "Epoch: [162][0/98]\t\n",
      "Epoch: [162][50/98]\t\n",
      "Epoch: [163][0/98]\t\n",
      "Epoch: [163][50/98]\t\n",
      "Epoch: [164][0/98]\t\n",
      "Epoch: [164][50/98]\t\n",
      "Epoch: [165][0/98]\t\n",
      "Epoch: [165][50/98]\t\n",
      "Epoch: [166][0/98]\t\n",
      "Epoch: [166][50/98]\t\n",
      "Epoch: [167][0/98]\t\n",
      "Epoch: [167][50/98]\t\n",
      "Epoch: [168][0/98]\t\n",
      "Epoch: [168][50/98]\t\n",
      "Epoch: [169][0/98]\t\n",
      "Epoch: [169][50/98]\t\n",
      "Epoch: [170][0/98]\t\n",
      "Epoch: [170][50/98]\t\n",
      "Epoch: [171][0/98]\t\n",
      "Epoch: [171][50/98]\t\n",
      "Epoch: [172][0/98]\t\n",
      "Epoch: [172][50/98]\t\n",
      "Epoch: [173][0/98]\t\n",
      "Epoch: [173][50/98]\t\n",
      "Epoch: [174][0/98]\t\n",
      "Epoch: [174][50/98]\t\n",
      "Epoch: [175][0/98]\t\n",
      "Epoch: [175][50/98]\t\n",
      "Epoch: [176][0/98]\t\n",
      "Epoch: [176][50/98]\t\n",
      "Epoch: [177][0/98]\t\n",
      "Epoch: [177][50/98]\t\n",
      "Epoch: [178][0/98]\t\n",
      "Epoch: [178][50/98]\t\n",
      "Epoch: [179][0/98]\t\n",
      "Epoch: [179][50/98]\t\n",
      "Epoch: [180][0/98]\t\n",
      "Epoch: [180][50/98]\t\n",
      "Epoch: [181][0/98]\t\n",
      "Epoch: [181][50/98]\t\n",
      "Epoch: [182][0/98]\t\n",
      "Epoch: [182][50/98]\t\n",
      "Epoch: [183][0/98]\t\n",
      "Epoch: [183][50/98]\t\n",
      "Epoch: [184][0/98]\t\n",
      "Epoch: [184][50/98]\t\n",
      "Epoch: [185][0/98]\t\n",
      "Epoch: [185][50/98]\t\n",
      "Epoch: [186][0/98]\t\n",
      "Epoch: [186][50/98]\t\n",
      "Epoch: [187][0/98]\t\n",
      "Epoch: [187][50/98]\t\n",
      "Epoch: [188][0/98]\t\n",
      "Epoch: [188][50/98]\t\n",
      "Epoch: [189][0/98]\t\n",
      "Epoch: [189][50/98]\t\n",
      "Epoch: [190][0/98]\t\n",
      "Epoch: [190][50/98]\t\n",
      "Epoch: [191][0/98]\t\n",
      "Epoch: [191][50/98]\t\n",
      "Epoch: [192][0/98]\t\n",
      "Epoch: [192][50/98]\t\n",
      "Epoch: [193][0/98]\t\n",
      "Epoch: [193][50/98]\t\n",
      "Epoch: [194][0/98]\t\n",
      "Epoch: [194][50/98]\t\n",
      "Epoch: [195][0/98]\t\n",
      "Epoch: [195][50/98]\t\n",
      "Epoch: [196][0/98]\t\n",
      "Epoch: [196][50/98]\t\n",
      "Epoch: [197][0/98]\t\n",
      "Epoch: [197][50/98]\t\n",
      "Epoch: [198][0/98]\t\n",
      "Epoch: [198][50/98]\t\n",
      "Epoch: [199][0/98]\t\n",
      "Epoch: [199][50/98]\t\n",
      "Training using Adam optimzer\n",
      "Epoch: [0][0/98]\t\n",
      "Epoch: [0][50/98]\t\n",
      "Epoch: [1][0/98]\t\n",
      "Epoch: [1][50/98]\t\n",
      "Epoch: [2][0/98]\t\n",
      "Epoch: [2][50/98]\t\n",
      "Epoch: [3][0/98]\t\n",
      "Epoch: [3][50/98]\t\n",
      "Epoch: [4][0/98]\t\n",
      "Epoch: [4][50/98]\t\n",
      "Epoch: [5][0/98]\t\n",
      "Epoch: [5][50/98]\t\n",
      "Epoch: [6][0/98]\t\n",
      "Epoch: [6][50/98]\t\n",
      "Epoch: [7][0/98]\t\n",
      "Epoch: [7][50/98]\t\n",
      "Epoch: [8][0/98]\t\n",
      "Epoch: [8][50/98]\t\n",
      "Epoch: [9][0/98]\t\n",
      "Epoch: [9][50/98]\t\n",
      "Epoch: [10][0/98]\t\n",
      "Epoch: [10][50/98]\t\n",
      "Epoch: [11][0/98]\t\n",
      "Epoch: [11][50/98]\t\n",
      "Epoch: [12][0/98]\t\n",
      "Epoch: [12][50/98]\t\n",
      "Epoch: [13][0/98]\t\n",
      "Epoch: [13][50/98]\t\n",
      "Epoch: [14][0/98]\t\n",
      "Epoch: [14][50/98]\t\n",
      "Epoch: [15][0/98]\t\n",
      "Epoch: [15][50/98]\t\n",
      "Epoch: [16][0/98]\t\n",
      "Epoch: [16][50/98]\t\n",
      "Epoch: [17][0/98]\t\n",
      "Epoch: [17][50/98]\t\n",
      "Epoch: [18][0/98]\t\n",
      "Epoch: [18][50/98]\t\n",
      "Epoch: [19][0/98]\t\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [19][50/98]\t\n",
      "Epoch: [20][0/98]\t\n",
      "Epoch: [20][50/98]\t\n",
      "Epoch: [21][0/98]\t\n",
      "Epoch: [21][50/98]\t\n",
      "Epoch: [22][0/98]\t\n",
      "Epoch: [22][50/98]\t\n",
      "Epoch: [23][0/98]\t\n",
      "Epoch: [23][50/98]\t\n",
      "Epoch: [24][0/98]\t\n",
      "Epoch: [24][50/98]\t\n",
      "Epoch: [25][0/98]\t\n",
      "Epoch: [25][50/98]\t\n",
      "Epoch: [26][0/98]\t\n",
      "Epoch: [26][50/98]\t\n",
      "Epoch: [27][0/98]\t\n",
      "Epoch: [27][50/98]\t\n",
      "Epoch: [28][0/98]\t\n",
      "Epoch: [28][50/98]\t\n",
      "Epoch: [29][0/98]\t\n",
      "Epoch: [29][50/98]\t\n",
      "Epoch: [30][0/98]\t\n",
      "Epoch: [30][50/98]\t\n",
      "Epoch: [31][0/98]\t\n",
      "Epoch: [31][50/98]\t\n",
      "Epoch: [32][0/98]\t\n",
      "Epoch: [32][50/98]\t\n",
      "Epoch: [33][0/98]\t\n",
      "Epoch: [33][50/98]\t\n",
      "Epoch: [34][0/98]\t\n",
      "Epoch: [34][50/98]\t\n",
      "Epoch: [35][0/98]\t\n",
      "Epoch: [35][50/98]\t\n",
      "Epoch: [36][0/98]\t\n",
      "Epoch: [36][50/98]\t\n",
      "Epoch: [37][0/98]\t\n",
      "Epoch: [37][50/98]\t\n",
      "Epoch: [38][0/98]\t\n",
      "Epoch: [38][50/98]\t\n",
      "Epoch: [39][0/98]\t\n",
      "Epoch: [39][50/98]\t\n",
      "Epoch: [40][0/98]\t\n",
      "Epoch: [40][50/98]\t\n",
      "Epoch: [41][0/98]\t\n",
      "Epoch: [41][50/98]\t\n",
      "Epoch: [42][0/98]\t\n",
      "Epoch: [42][50/98]\t\n",
      "Epoch: [43][0/98]\t\n",
      "Epoch: [43][50/98]\t\n",
      "Epoch: [44][0/98]\t\n",
      "Epoch: [44][50/98]\t\n",
      "Epoch: [45][0/98]\t\n",
      "Epoch: [45][50/98]\t\n",
      "Epoch: [46][0/98]\t\n",
      "Epoch: [46][50/98]\t\n",
      "Epoch: [47][0/98]\t\n",
      "Epoch: [47][50/98]\t\n",
      "Epoch: [48][0/98]\t\n",
      "Epoch: [48][50/98]\t\n",
      "Epoch: [49][0/98]\t\n",
      "Epoch: [49][50/98]\t\n",
      "Epoch: [50][0/98]\t\n",
      "Epoch: [50][50/98]\t\n",
      "Epoch: [51][0/98]\t\n",
      "Epoch: [51][50/98]\t\n",
      "Epoch: [52][0/98]\t\n",
      "Epoch: [52][50/98]\t\n",
      "Epoch: [53][0/98]\t\n",
      "Epoch: [53][50/98]\t\n",
      "Epoch: [54][0/98]\t\n",
      "Epoch: [54][50/98]\t\n",
      "Epoch: [55][0/98]\t\n",
      "Epoch: [55][50/98]\t\n",
      "Epoch: [56][0/98]\t\n",
      "Epoch: [56][50/98]\t\n",
      "Epoch: [57][0/98]\t\n",
      "Epoch: [57][50/98]\t\n",
      "Epoch: [58][0/98]\t\n",
      "Epoch: [58][50/98]\t\n",
      "Epoch: [59][0/98]\t\n",
      "Epoch: [59][50/98]\t\n",
      "Epoch: [60][0/98]\t\n",
      "Epoch: [60][50/98]\t\n",
      "Epoch: [61][0/98]\t\n",
      "Epoch: [61][50/98]\t\n",
      "Epoch: [62][0/98]\t\n",
      "Epoch: [62][50/98]\t\n",
      "Epoch: [63][0/98]\t\n",
      "Epoch: [63][50/98]\t\n",
      "Epoch: [64][0/98]\t\n",
      "Epoch: [64][50/98]\t\n",
      "Epoch: [65][0/98]\t\n",
      "Epoch: [65][50/98]\t\n",
      "Epoch: [66][0/98]\t\n",
      "Epoch: [66][50/98]\t\n",
      "Epoch: [67][0/98]\t\n",
      "Epoch: [67][50/98]\t\n",
      "Epoch: [68][0/98]\t\n",
      "Epoch: [68][50/98]\t\n",
      "Epoch: [69][0/98]\t\n",
      "Epoch: [69][50/98]\t\n",
      "Epoch: [70][0/98]\t\n",
      "Epoch: [70][50/98]\t\n",
      "Epoch: [71][0/98]\t\n",
      "Epoch: [71][50/98]\t\n",
      "Epoch: [72][0/98]\t\n",
      "Epoch: [72][50/98]\t\n",
      "Epoch: [73][0/98]\t\n",
      "Epoch: [73][50/98]\t\n",
      "Epoch: [74][0/98]\t\n",
      "Epoch: [74][50/98]\t\n",
      "Epoch: [75][0/98]\t\n",
      "Epoch: [75][50/98]\t\n",
      "Epoch: [76][0/98]\t\n",
      "Epoch: [76][50/98]\t\n",
      "Epoch: [77][0/98]\t\n",
      "Epoch: [77][50/98]\t\n",
      "Epoch: [78][0/98]\t\n",
      "Epoch: [78][50/98]\t\n",
      "Epoch: [79][0/98]\t\n",
      "Epoch: [79][50/98]\t\n",
      "Epoch: [80][0/98]\t\n",
      "Epoch: [80][50/98]\t\n",
      "Epoch: [81][0/98]\t\n",
      "Epoch: [81][50/98]\t\n",
      "Epoch: [82][0/98]\t\n",
      "Epoch: [82][50/98]\t\n",
      "Epoch: [83][0/98]\t\n",
      "Epoch: [83][50/98]\t\n",
      "Epoch: [84][0/98]\t\n",
      "Epoch: [84][50/98]\t\n",
      "Epoch: [85][0/98]\t\n",
      "Epoch: [85][50/98]\t\n",
      "Epoch: [86][0/98]\t\n",
      "Epoch: [86][50/98]\t\n",
      "Epoch: [87][0/98]\t\n",
      "Epoch: [87][50/98]\t\n",
      "Epoch: [88][0/98]\t\n",
      "Epoch: [88][50/98]\t\n",
      "Epoch: [89][0/98]\t\n",
      "Epoch: [89][50/98]\t\n",
      "Epoch: [90][0/98]\t\n",
      "Epoch: [90][50/98]\t\n",
      "Epoch: [91][0/98]\t\n",
      "Epoch: [91][50/98]\t\n",
      "Epoch: [92][0/98]\t\n",
      "Epoch: [92][50/98]\t\n",
      "Epoch: [93][0/98]\t\n",
      "Epoch: [93][50/98]\t\n",
      "Epoch: [94][0/98]\t\n",
      "Epoch: [94][50/98]\t\n",
      "Epoch: [95][0/98]\t\n",
      "Epoch: [95][50/98]\t\n",
      "Epoch: [96][0/98]\t\n",
      "Epoch: [96][50/98]\t\n",
      "Epoch: [97][0/98]\t\n",
      "Epoch: [97][50/98]\t\n",
      "Epoch: [98][0/98]\t\n",
      "Epoch: [98][50/98]\t\n",
      "Epoch: [99][0/98]\t\n",
      "Epoch: [99][50/98]\t\n",
      "Epoch: [100][0/98]\t\n",
      "Epoch: [100][50/98]\t\n",
      "Epoch: [101][0/98]\t\n",
      "Epoch: [101][50/98]\t\n",
      "Epoch: [102][0/98]\t\n",
      "Epoch: [102][50/98]\t\n",
      "Epoch: [103][0/98]\t\n",
      "Epoch: [103][50/98]\t\n",
      "Epoch: [104][0/98]\t\n",
      "Epoch: [104][50/98]\t\n",
      "Epoch: [105][0/98]\t\n",
      "Epoch: [105][50/98]\t\n",
      "Epoch: [106][0/98]\t\n",
      "Epoch: [106][50/98]\t\n",
      "Epoch: [107][0/98]\t\n",
      "Epoch: [107][50/98]\t\n",
      "Epoch: [108][0/98]\t\n",
      "Epoch: [108][50/98]\t\n",
      "Epoch: [109][0/98]\t\n",
      "Epoch: [109][50/98]\t\n",
      "Epoch: [110][0/98]\t\n",
      "Epoch: [110][50/98]\t\n",
      "Epoch: [111][0/98]\t\n",
      "Epoch: [111][50/98]\t\n",
      "Epoch: [112][0/98]\t\n",
      "Epoch: [112][50/98]\t\n",
      "Epoch: [113][0/98]\t\n",
      "Epoch: [113][50/98]\t\n",
      "Epoch: [114][0/98]\t\n",
      "Epoch: [114][50/98]\t\n",
      "Epoch: [115][0/98]\t\n",
      "Epoch: [115][50/98]\t\n",
      "Epoch: [116][0/98]\t\n",
      "Epoch: [116][50/98]\t\n",
      "Epoch: [117][0/98]\t\n",
      "Epoch: [117][50/98]\t\n",
      "Epoch: [118][0/98]\t\n",
      "Epoch: [118][50/98]\t\n",
      "Epoch: [119][0/98]\t\n",
      "Epoch: [119][50/98]\t\n",
      "Epoch: [120][0/98]\t\n",
      "Epoch: [120][50/98]\t\n",
      "Epoch: [121][0/98]\t\n",
      "Epoch: [121][50/98]\t\n",
      "Epoch: [122][0/98]\t\n",
      "Epoch: [122][50/98]\t\n",
      "Epoch: [123][0/98]\t\n",
      "Epoch: [123][50/98]\t\n",
      "Epoch: [124][0/98]\t\n",
      "Epoch: [124][50/98]\t\n",
      "Epoch: [125][0/98]\t\n",
      "Epoch: [125][50/98]\t\n",
      "Epoch: [126][0/98]\t\n",
      "Epoch: [126][50/98]\t\n",
      "Epoch: [127][0/98]\t\n",
      "Epoch: [127][50/98]\t\n",
      "Epoch: [128][0/98]\t\n",
      "Epoch: [128][50/98]\t\n",
      "Epoch: [129][0/98]\t\n",
      "Epoch: [129][50/98]\t\n",
      "Epoch: [130][0/98]\t\n",
      "Epoch: [130][50/98]\t\n",
      "Epoch: [131][0/98]\t\n",
      "Epoch: [131][50/98]\t\n",
      "Epoch: [132][0/98]\t\n",
      "Epoch: [132][50/98]\t\n",
      "Epoch: [133][0/98]\t\n",
      "Epoch: [133][50/98]\t\n",
      "Epoch: [134][0/98]\t\n",
      "Epoch: [134][50/98]\t\n",
      "Epoch: [135][0/98]\t\n",
      "Epoch: [135][50/98]\t\n",
      "Epoch: [136][0/98]\t\n",
      "Epoch: [136][50/98]\t\n",
      "Epoch: [137][0/98]\t\n",
      "Epoch: [137][50/98]\t\n",
      "Epoch: [138][0/98]\t\n",
      "Epoch: [138][50/98]\t\n",
      "Epoch: [139][0/98]\t\n",
      "Epoch: [139][50/98]\t\n",
      "Epoch: [140][0/98]\t\n",
      "Epoch: [140][50/98]\t\n",
      "Epoch: [141][0/98]\t\n",
      "Epoch: [141][50/98]\t\n",
      "Epoch: [142][0/98]\t\n",
      "Epoch: [142][50/98]\t\n",
      "Epoch: [143][0/98]\t\n",
      "Epoch: [143][50/98]\t\n",
      "Epoch: [144][0/98]\t\n",
      "Epoch: [144][50/98]\t\n",
      "Epoch: [145][0/98]\t\n",
      "Epoch: [145][50/98]\t\n",
      "Epoch: [146][0/98]\t\n",
      "Epoch: [146][50/98]\t\n",
      "Epoch: [147][0/98]\t\n",
      "Epoch: [147][50/98]\t\n",
      "Epoch: [148][0/98]\t\n",
      "Epoch: [148][50/98]\t\n",
      "Epoch: [149][0/98]\t\n",
      "Epoch: [149][50/98]\t\n",
      "Epoch: [150][0/98]\t\n",
      "Epoch: [150][50/98]\t\n",
      "Epoch: [151][0/98]\t\n",
      "Epoch: [151][50/98]\t\n",
      "Epoch: [152][0/98]\t\n",
      "Epoch: [152][50/98]\t\n",
      "Epoch: [153][0/98]\t\n",
      "Epoch: [153][50/98]\t\n",
      "Epoch: [154][0/98]\t\n",
      "Epoch: [154][50/98]\t\n",
      "Epoch: [155][0/98]\t\n",
      "Epoch: [155][50/98]\t\n",
      "Epoch: [156][0/98]\t\n",
      "Epoch: [156][50/98]\t\n",
      "Epoch: [157][0/98]\t\n",
      "Epoch: [157][50/98]\t\n",
      "Epoch: [158][0/98]\t\n",
      "Epoch: [158][50/98]\t\n",
      "Epoch: [159][0/98]\t\n",
      "Epoch: [159][50/98]\t\n",
      "Epoch: [160][0/98]\t\n",
      "Epoch: [160][50/98]\t\n",
      "Epoch: [161][0/98]\t\n",
      "Epoch: [161][50/98]\t\n",
      "Epoch: [162][0/98]\t\n",
      "Epoch: [162][50/98]\t\n",
      "Epoch: [163][0/98]\t\n",
      "Epoch: [163][50/98]\t\n",
      "Epoch: [164][0/98]\t\n",
      "Epoch: [164][50/98]\t\n",
      "Epoch: [165][0/98]\t\n",
      "Epoch: [165][50/98]\t\n",
      "Epoch: [166][0/98]\t\n",
      "Epoch: [166][50/98]\t\n",
      "Epoch: [167][0/98]\t\n",
      "Epoch: [167][50/98]\t\n",
      "Epoch: [168][0/98]\t\n",
      "Epoch: [168][50/98]\t\n",
      "Epoch: [169][0/98]\t\n",
      "Epoch: [169][50/98]\t\n",
      "Epoch: [170][0/98]\t\n",
      "Epoch: [170][50/98]\t\n",
      "Epoch: [171][0/98]\t\n",
      "Epoch: [171][50/98]\t\n",
      "Epoch: [172][0/98]\t\n",
      "Epoch: [172][50/98]\t\n",
      "Epoch: [173][0/98]\t\n",
      "Epoch: [173][50/98]\t\n",
      "Epoch: [174][0/98]\t\n",
      "Epoch: [174][50/98]\t\n",
      "Epoch: [175][0/98]\t\n",
      "Epoch: [175][50/98]\t\n",
      "Epoch: [176][0/98]\t\n",
      "Epoch: [176][50/98]\t\n",
      "Epoch: [177][0/98]\t\n",
      "Epoch: [177][50/98]\t\n",
      "Epoch: [178][0/98]\t\n",
      "Epoch: [178][50/98]\t\n",
      "Epoch: [179][0/98]\t\n",
      "Epoch: [179][50/98]\t\n",
      "Epoch: [180][0/98]\t\n",
      "Epoch: [180][50/98]\t\n",
      "Epoch: [181][0/98]\t\n",
      "Epoch: [181][50/98]\t\n",
      "Epoch: [182][0/98]\t\n",
      "Epoch: [182][50/98]\t\n",
      "Epoch: [183][0/98]\t\n",
      "Epoch: [183][50/98]\t\n",
      "Epoch: [184][0/98]\t\n",
      "Epoch: [184][50/98]\t\n",
      "Epoch: [185][0/98]\t\n",
      "Epoch: [185][50/98]\t\n",
      "Epoch: [186][0/98]\t\n",
      "Epoch: [186][50/98]\t\n",
      "Epoch: [187][0/98]\t\n",
      "Epoch: [187][50/98]\t\n",
      "Epoch: [188][0/98]\t\n",
      "Epoch: [188][50/98]\t\n",
      "Epoch: [189][0/98]\t\n",
      "Epoch: [189][50/98]\t\n",
      "Epoch: [190][0/98]\t\n",
      "Epoch: [190][50/98]\t\n",
      "Epoch: [191][0/98]\t\n",
      "Epoch: [191][50/98]\t\n",
      "Epoch: [192][0/98]\t\n",
      "Epoch: [192][50/98]\t\n",
      "Epoch: [193][0/98]\t\n",
      "Epoch: [193][50/98]\t\n",
      "Epoch: [194][0/98]\t\n",
      "Epoch: [194][50/98]\t\n",
      "Epoch: [195][0/98]\t\n",
      "Epoch: [195][50/98]\t\n",
      "Epoch: [196][0/98]\t\n",
      "Epoch: [196][50/98]\t\n",
      "Epoch: [197][0/98]\t\n",
      "Epoch: [197][50/98]\t\n",
      "Epoch: [198][0/98]\t\n",
      "Epoch: [198][50/98]\t\n",
      "Epoch: [199][0/98]\t\n",
      "Epoch: [199][50/98]\t\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adagrad, RMSprop, Adadelta, Adam\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_epochs, learning_rate, reg = 200, 1e-3, 1e-3\n",
    "def RMSNest(*args, **kwargs):\n",
    "    return RMSprop(*args, **kwargs)\n",
    "\n",
    "RMSNest.__name__ = \"RMSProp+Nesterov\"\n",
    "\n",
    "optim_t = [Adagrad, RMSprop, RMSNest, Adadelta, Adam]\n",
    "\n",
    "metrics = []\n",
    "for optim in optim_t:\n",
    "    print(f\"Training using {optim.__name__} optimzer\")\n",
    "    model = Net()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if optim == RMSNest:\n",
    "        optimizer = optim(model.parameters(), lr=learning_rate, weight_decay=reg, momentum=0.8)\n",
    "    else:\n",
    "        optimizer = optim(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "    \n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 60, 80])\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        losses.append(train_loss(trainloader, model, criterion, optimizer, device, epoch))\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "    accuracy = get_accuracy(valloader, model)\n",
    "    \n",
    "    metrics.append((losses, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb364218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, losses in enumerate(metrics):\n",
    "#     if optim_t[i].__name__ == \"RMSProp+Nesterov\":\n",
    "#         continue\n",
    "    plt.plot(range(n_epochs), losses[0], label=optim_t[i].__name__)\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4fa4a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.notification.emailer import *\n",
    "\n",
    "msg = message.email(text=\"Q1 Training Done.\", subject=\"IDLS Lab Notebook Notification\")\n",
    "mail_io.send(msg, server=\"smtp.gmail.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081eabb8",
   "metadata": {},
   "source": [
    "## Data Parallelism in Pytorch\n",
    "### Q2.1\n",
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7bdc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=128, shuffle=True,\n",
    "        num_workers=2, pin_memory=True)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=100, shuffle=False,\n",
    "        num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71027397",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b0f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f18471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    print_freq = 50\n",
    "    l = len(train_loader)\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    \n",
    "    runtime = 0\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "        start = datetime.now()\n",
    "        target = target.to(device)\n",
    "        input_var = inputs.to(device)\n",
    "        target_var = target\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        runtime += (datetime.now() - start).total_seconds()\n",
    "        \n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'.format(epoch, i, l))\n",
    "        \n",
    "    return runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d919a40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Files already downloaded and verified\n",
      "Batch Size: 32\n",
      "Epoch: [0][0/1563]\t\n",
      "Epoch: [0][50/1563]\t\n",
      "Epoch: [0][100/1563]\t\n",
      "Epoch: [0][150/1563]\t\n",
      "Epoch: [0][200/1563]\t\n",
      "Epoch: [0][250/1563]\t\n",
      "Epoch: [0][300/1563]\t\n",
      "Epoch: [0][350/1563]\t\n",
      "Epoch: [0][400/1563]\t\n",
      "Epoch: [0][450/1563]\t\n",
      "Epoch: [0][500/1563]\t\n",
      "Epoch: [0][550/1563]\t\n",
      "Epoch: [0][600/1563]\t\n",
      "Epoch: [0][650/1563]\t\n",
      "Epoch: [0][700/1563]\t\n",
      "Epoch: [0][750/1563]\t\n",
      "Epoch: [0][800/1563]\t\n",
      "Epoch: [0][850/1563]\t\n",
      "Epoch: [0][900/1563]\t\n",
      "Epoch: [0][950/1563]\t\n",
      "Epoch: [0][1000/1563]\t\n",
      "Epoch: [0][1050/1563]\t\n",
      "Epoch: [0][1100/1563]\t\n",
      "Epoch: [0][1150/1563]\t\n",
      "Epoch: [0][1200/1563]\t\n",
      "Epoch: [0][1250/1563]\t\n",
      "Epoch: [0][1300/1563]\t\n",
      "Epoch: [0][1350/1563]\t\n",
      "Epoch: [0][1400/1563]\t\n",
      "Epoch: [0][1450/1563]\t\n",
      "Epoch: [0][1500/1563]\t\n",
      "Epoch: [0][1550/1563]\t\n",
      "Batch Size: 32\n",
      "Epoch: [1][0/1563]\t\n",
      "Epoch: [1][50/1563]\t\n",
      "Epoch: [1][100/1563]\t\n",
      "Epoch: [1][150/1563]\t\n",
      "Epoch: [1][200/1563]\t\n",
      "Epoch: [1][250/1563]\t\n",
      "Epoch: [1][300/1563]\t\n",
      "Epoch: [1][350/1563]\t\n",
      "Epoch: [1][400/1563]\t\n",
      "Epoch: [1][450/1563]\t\n",
      "Epoch: [1][500/1563]\t\n",
      "Epoch: [1][550/1563]\t\n",
      "Epoch: [1][600/1563]\t\n",
      "Epoch: [1][650/1563]\t\n",
      "Epoch: [1][700/1563]\t\n",
      "Epoch: [1][750/1563]\t\n",
      "Epoch: [1][800/1563]\t\n",
      "Epoch: [1][850/1563]\t\n",
      "Epoch: [1][900/1563]\t\n",
      "Epoch: [1][950/1563]\t\n",
      "Epoch: [1][1000/1563]\t\n",
      "Epoch: [1][1050/1563]\t\n",
      "Epoch: [1][1100/1563]\t\n",
      "Epoch: [1][1150/1563]\t\n",
      "Epoch: [1][1200/1563]\t\n",
      "Epoch: [1][1250/1563]\t\n",
      "Epoch: [1][1300/1563]\t\n",
      "Epoch: [1][1350/1563]\t\n",
      "Epoch: [1][1400/1563]\t\n",
      "Epoch: [1][1450/1563]\t\n",
      "Epoch: [1][1500/1563]\t\n",
      "Epoch: [1][1550/1563]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 128\n",
      "Epoch: [0][0/391]\t\n",
      "Epoch: [0][50/391]\t\n",
      "Epoch: [0][100/391]\t\n",
      "Epoch: [0][150/391]\t\n",
      "Epoch: [0][200/391]\t\n",
      "Epoch: [0][250/391]\t\n",
      "Epoch: [0][300/391]\t\n",
      "Epoch: [0][350/391]\t\n",
      "Batch Size: 128\n",
      "Epoch: [1][0/391]\t\n",
      "Epoch: [1][50/391]\t\n",
      "Epoch: [1][100/391]\t\n",
      "Epoch: [1][150/391]\t\n",
      "Epoch: [1][200/391]\t\n",
      "Epoch: [1][250/391]\t\n",
      "Epoch: [1][300/391]\t\n",
      "Epoch: [1][350/391]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 512\n",
      "Epoch: [0][0/98]\t\n",
      "Epoch: [0][50/98]\t\n",
      "Batch Size: 512\n",
      "Epoch: [1][0/98]\t\n",
      "Epoch: [1][50/98]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 2048\n",
      "Epoch: [0][0/25]\t\n",
      "Batch Size: 2048\n",
      "Epoch: [1][0/25]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 8192\n",
      "CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 31.75 GiB total capacity; 28.27 GiB already allocated; 843.75 MiB free; 29.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "size = 32\n",
    "train_times_g1 = []\n",
    "n_epochs = 2\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=size, shuffle=True,\n",
    "        num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = ResNet18()\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), 0.1,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=5e-4)\n",
    "\n",
    "        runtimes = []\n",
    "        for epoch in range(n_epochs):\n",
    "            print(f\"Batch Size: {size}\")\n",
    "            runtimes.append(train(trainloader, model, criterion, optimizer, device))\n",
    "\n",
    "        train_times_g1.append(runtimes[-1])\n",
    "        \n",
    "        size *= 4\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77cc1678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU Compute Time\n",
      "Batch Size, Training Time(s)\n",
      "32, 27.438\n",
      "128, 17.857\n",
      "512, 18.398\n",
      "2048, 18.061\n"
     ]
    }
   ],
   "source": [
    "print(\"Single GPU Compute Time\")\n",
    "print(\"Batch Size, Training Time(s)\")\n",
    "i = 0\n",
    "while i < len(train_times_g1):\n",
    "    print(f\"{32*(4**i)}, {train_times_g1[i]:.3f}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e19611",
   "metadata": {},
   "source": [
    "### Q2.2\n",
    "#### 2 GPU performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1adc62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Batch Size: 32\n",
      "Epoch: [0][0/1563]\t\n",
      "Epoch: [0][50/1563]\t\n",
      "Epoch: [0][100/1563]\t\n",
      "Epoch: [0][150/1563]\t\n",
      "Epoch: [0][200/1563]\t\n",
      "Epoch: [0][250/1563]\t\n",
      "Epoch: [0][300/1563]\t\n",
      "Epoch: [0][350/1563]\t\n",
      "Epoch: [0][400/1563]\t\n",
      "Epoch: [0][450/1563]\t\n",
      "Epoch: [0][500/1563]\t\n",
      "Epoch: [0][550/1563]\t\n",
      "Epoch: [0][600/1563]\t\n",
      "Epoch: [0][650/1563]\t\n",
      "Epoch: [0][700/1563]\t\n",
      "Epoch: [0][750/1563]\t\n",
      "Epoch: [0][800/1563]\t\n",
      "Epoch: [0][850/1563]\t\n",
      "Epoch: [0][900/1563]\t\n",
      "Epoch: [0][950/1563]\t\n",
      "Epoch: [0][1000/1563]\t\n",
      "Epoch: [0][1050/1563]\t\n",
      "Epoch: [0][1100/1563]\t\n",
      "Epoch: [0][1150/1563]\t\n",
      "Epoch: [0][1200/1563]\t\n",
      "Epoch: [0][1250/1563]\t\n",
      "Epoch: [0][1300/1563]\t\n",
      "Epoch: [0][1350/1563]\t\n",
      "Epoch: [0][1400/1563]\t\n",
      "Epoch: [0][1450/1563]\t\n",
      "Epoch: [0][1500/1563]\t\n",
      "Epoch: [0][1550/1563]\t\n",
      "Batch Size: 32\n",
      "Epoch: [1][0/1563]\t\n",
      "Epoch: [1][50/1563]\t\n",
      "Epoch: [1][100/1563]\t\n",
      "Epoch: [1][150/1563]\t\n",
      "Epoch: [1][200/1563]\t\n",
      "Epoch: [1][250/1563]\t\n",
      "Epoch: [1][300/1563]\t\n",
      "Epoch: [1][350/1563]\t\n",
      "Epoch: [1][400/1563]\t\n",
      "Epoch: [1][450/1563]\t\n",
      "Epoch: [1][500/1563]\t\n",
      "Epoch: [1][550/1563]\t\n",
      "Epoch: [1][600/1563]\t\n",
      "Epoch: [1][650/1563]\t\n",
      "Epoch: [1][700/1563]\t\n",
      "Epoch: [1][750/1563]\t\n",
      "Epoch: [1][800/1563]\t\n",
      "Epoch: [1][850/1563]\t\n",
      "Epoch: [1][900/1563]\t\n",
      "Epoch: [1][950/1563]\t\n",
      "Epoch: [1][1000/1563]\t\n",
      "Epoch: [1][1050/1563]\t\n",
      "Epoch: [1][1100/1563]\t\n",
      "Epoch: [1][1150/1563]\t\n",
      "Epoch: [1][1200/1563]\t\n",
      "Epoch: [1][1250/1563]\t\n",
      "Epoch: [1][1300/1563]\t\n",
      "Epoch: [1][1350/1563]\t\n",
      "Epoch: [1][1400/1563]\t\n",
      "Epoch: [1][1450/1563]\t\n",
      "Epoch: [1][1500/1563]\t\n",
      "Epoch: [1][1550/1563]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 128\n",
      "Epoch: [0][0/391]\t\n",
      "Epoch: [0][50/391]\t\n",
      "Epoch: [0][100/391]\t\n",
      "Epoch: [0][150/391]\t\n",
      "Epoch: [0][200/391]\t\n",
      "Epoch: [0][250/391]\t\n",
      "Epoch: [0][300/391]\t\n",
      "Epoch: [0][350/391]\t\n",
      "Batch Size: 128\n",
      "Epoch: [1][0/391]\t\n",
      "Epoch: [1][50/391]\t\n",
      "Epoch: [1][100/391]\t\n",
      "Epoch: [1][150/391]\t\n",
      "Epoch: [1][200/391]\t\n",
      "Epoch: [1][250/391]\t\n",
      "Epoch: [1][300/391]\t\n",
      "Epoch: [1][350/391]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 512\n",
      "Epoch: [0][0/98]\t\n",
      "Epoch: [0][50/98]\t\n",
      "Batch Size: 512\n",
      "Epoch: [1][0/98]\t\n",
      "Epoch: [1][50/98]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 2048\n",
      "Epoch: [0][0/25]\t\n",
      "Batch Size: 2048\n",
      "Epoch: [1][0/25]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 8192\n",
      "Epoch: [0][0/7]\t\n",
      "Batch Size: 8192\n",
      "Epoch: [1][0/7]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 32768\n",
      "Caught RuntimeError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<ipython-input-4-e07a392df452>\", line 86, in forward\n",
      "    out = self.layer1(out)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<ipython-input-4-e07a392df452>\", line 24, in forward\n",
      "    out = F.relu(self.bn1(self.conv1(x)))\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", line 168, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/functional.py\", line 2282, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 31.75 GiB total capacity; 28.55 GiB already allocated; 85.75 MiB free; 30.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "size=32\n",
    "train_times_g2 = []\n",
    "compute_times_g2 = []\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start = datetime.now()\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=size, shuffle=True,\n",
    "        num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = ResNet18()\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), 0.1,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=5e-4)\n",
    "\n",
    "        train_time = (datetime.now() - start).total_seconds()\n",
    "\n",
    "        runtimes = []\n",
    "        for epoch in range(n_epochs):\n",
    "            print(f\"Batch Size: {size}\")\n",
    "            runtimes.append(train(trainloader, model, criterion, optimizer, device))\n",
    "\n",
    "        train_time += runtimes[-1]\n",
    "        train_times_g2.append(train_time)\n",
    "        compute_times_g2.append(runtimes[-1])\n",
    "        \n",
    "        size *= 4\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2d6fddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPU Training Time (with Data Load)\n",
      "Batch Size, Training Time(s)\n",
      "32, 50.353\n",
      "128, 20.399\n",
      "512, 13.410\n",
      "2048, 6.652\n",
      "8192, 6.543\n"
     ]
    }
   ],
   "source": [
    "print(\"2 GPU Training Time (with Data Load)\")\n",
    "print(\"Batch Size, Training Time(s)\")\n",
    "i = 0\n",
    "while i < len(train_times_g2):\n",
    "    print(f\"{32*(4**i)}, {train_times_g2[i]:.3f}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7602a115",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPU Training Time (without Data Load)\n",
      "Batch Size, Training Time(s)\n",
      "32, 50.353\n",
      "128, 20.399\n",
      "512, 13.410\n",
      "2048, 6.652\n",
      "8192, 6.543\n"
     ]
    }
   ],
   "source": [
    "print(\"2 GPU Training Time (without Data Load)\")\n",
    "print(\"Batch Size, Training Time(s)\")\n",
    "i = 0\n",
    "while i < len(train_times_g2):\n",
    "    print(f\"{32*(4**i)}, {train_times_g2[i]:.3f}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be4b4c",
   "metadata": {},
   "source": [
    "#### 4 GPU Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65c938a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Batch Size: 32\n",
      "Epoch: [0][0/1563]\t\n",
      "Epoch: [0][50/1563]\t\n",
      "Epoch: [0][100/1563]\t\n",
      "Epoch: [0][150/1563]\t\n",
      "Epoch: [0][200/1563]\t\n",
      "Epoch: [0][250/1563]\t\n",
      "Epoch: [0][300/1563]\t\n",
      "Epoch: [0][350/1563]\t\n",
      "Epoch: [0][400/1563]\t\n",
      "Epoch: [0][450/1563]\t\n",
      "Epoch: [0][500/1563]\t\n",
      "Epoch: [0][550/1563]\t\n",
      "Epoch: [0][600/1563]\t\n",
      "Epoch: [0][650/1563]\t\n",
      "Epoch: [0][700/1563]\t\n",
      "Epoch: [0][750/1563]\t\n",
      "Epoch: [0][800/1563]\t\n",
      "Epoch: [0][850/1563]\t\n",
      "Epoch: [0][900/1563]\t\n",
      "Epoch: [0][950/1563]\t\n",
      "Epoch: [0][1000/1563]\t\n",
      "Epoch: [0][1050/1563]\t\n",
      "Epoch: [0][1100/1563]\t\n",
      "Epoch: [0][1150/1563]\t\n",
      "Epoch: [0][1200/1563]\t\n",
      "Epoch: [0][1250/1563]\t\n",
      "Epoch: [0][1300/1563]\t\n",
      "Epoch: [0][1350/1563]\t\n",
      "Epoch: [0][1400/1563]\t\n",
      "Epoch: [0][1450/1563]\t\n",
      "Epoch: [0][1500/1563]\t\n",
      "Epoch: [0][1550/1563]\t\n",
      "Batch Size: 32\n",
      "Epoch: [1][0/1563]\t\n",
      "Epoch: [1][50/1563]\t\n",
      "Epoch: [1][100/1563]\t\n",
      "Epoch: [1][150/1563]\t\n",
      "Epoch: [1][200/1563]\t\n",
      "Epoch: [1][250/1563]\t\n",
      "Epoch: [1][300/1563]\t\n",
      "Epoch: [1][350/1563]\t\n",
      "Epoch: [1][400/1563]\t\n",
      "Epoch: [1][450/1563]\t\n",
      "Epoch: [1][500/1563]\t\n",
      "Epoch: [1][550/1563]\t\n",
      "Epoch: [1][600/1563]\t\n",
      "Epoch: [1][650/1563]\t\n",
      "Epoch: [1][700/1563]\t\n",
      "Epoch: [1][750/1563]\t\n",
      "Epoch: [1][800/1563]\t\n",
      "Epoch: [1][850/1563]\t\n",
      "Epoch: [1][900/1563]\t\n",
      "Epoch: [1][950/1563]\t\n",
      "Epoch: [1][1000/1563]\t\n",
      "Epoch: [1][1050/1563]\t\n",
      "Epoch: [1][1100/1563]\t\n",
      "Epoch: [1][1150/1563]\t\n",
      "Epoch: [1][1200/1563]\t\n",
      "Epoch: [1][1250/1563]\t\n",
      "Epoch: [1][1300/1563]\t\n",
      "Epoch: [1][1350/1563]\t\n",
      "Epoch: [1][1400/1563]\t\n",
      "Epoch: [1][1450/1563]\t\n",
      "Epoch: [1][1500/1563]\t\n",
      "Epoch: [1][1550/1563]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 128\n",
      "Epoch: [0][0/391]\t\n",
      "Epoch: [0][50/391]\t\n",
      "Epoch: [0][100/391]\t\n",
      "Epoch: [0][150/391]\t\n",
      "Epoch: [0][200/391]\t\n",
      "Epoch: [0][250/391]\t\n",
      "Epoch: [0][300/391]\t\n",
      "Epoch: [0][350/391]\t\n",
      "Batch Size: 128\n",
      "Epoch: [1][0/391]\t\n",
      "Epoch: [1][50/391]\t\n",
      "Epoch: [1][100/391]\t\n",
      "Epoch: [1][150/391]\t\n",
      "Epoch: [1][200/391]\t\n",
      "Epoch: [1][250/391]\t\n",
      "Epoch: [1][300/391]\t\n",
      "Epoch: [1][350/391]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 512\n",
      "Epoch: [0][0/98]\t\n",
      "Epoch: [0][50/98]\t\n",
      "Batch Size: 512\n",
      "Epoch: [1][0/98]\t\n",
      "Epoch: [1][50/98]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 2048\n",
      "Epoch: [0][0/25]\t\n",
      "Batch Size: 2048\n",
      "Epoch: [1][0/25]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 8192\n",
      "Epoch: [0][0/7]\t\n",
      "Batch Size: 8192\n",
      "Epoch: [1][0/7]\t\n",
      "Files already downloaded and verified\n",
      "Batch Size: 32768\n",
      "Caught RuntimeError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<ipython-input-4-d22838ea95bd>\", line 56, in forward\n",
      "    out = self.layer2(out)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"<ipython-input-4-d22838ea95bd>\", line 25, in forward\n",
      "    out = self.bn2(self.conv2(out))\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", line 168, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/home/sj2810/.local/lib/python3.8/site-packages/torch/nn/functional.py\", line 2282, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 31.75 GiB total capacity; 28.42 GiB already allocated; 873.75 MiB free; 29.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "size=32\n",
    "train_times_g4 = []\n",
    "compute_times_g4 = []\n",
    "n_epochs = 2\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        start = datetime.now()\n",
    "        trainloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=size, shuffle=True,\n",
    "        num_workers=2, pin_memory=True)\n",
    "\n",
    "        model = ResNet18()\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        optimizer = torch.optim.SGD(model.parameters(), 0.1,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=5e-4)\n",
    "\n",
    "        train_time = (datetime.now() - start).total_seconds()\n",
    "\n",
    "        runtimes = []\n",
    "        for epoch in range(n_epochs):\n",
    "            print(f\"Batch Size: {size}\")\n",
    "            runtimes.append(train(trainloader, model, criterion, optimizer, device, epoch))\n",
    "\n",
    "        train_time += runtimes[-1]\n",
    "        train_times_g4.append(train_time)\n",
    "        compute_times_g4.append(runtimes[-1])\n",
    "        \n",
    "        size *= 4\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc4ad1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 GPU Training Time (with Data Load)\n",
      "Batch Size, Training Time(s)\n",
      "32, 59.304\n",
      "128, 17.801\n",
      "512, 6.393\n",
      "2048, 4.357\n",
      "8192, 4.608\n"
     ]
    }
   ],
   "source": [
    "print(\"4 GPU Training Time (with Data Load)\")\n",
    "print(\"Batch Size, Training Time(s)\")\n",
    "i = 0\n",
    "while i < len(train_times_g4):\n",
    "    print(f\"{32*(4**i)}, {train_times_g4[i]:.3f}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e0671a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 GPU Training Time (without Data Load)\n",
      "Batch Size, Training Time(s)\n",
      "32, 59.304\n",
      "128, 17.801\n",
      "512, 6.393\n",
      "2048, 4.357\n",
      "8192, 4.608\n"
     ]
    }
   ],
   "source": [
    "print(\"4 GPU Training Time (without Data Load)\")\n",
    "print(\"Batch Size, Training Time(s)\")\n",
    "i = 0\n",
    "while i < len(train_times_g4):\n",
    "    print(f\"{32*(4**i)}, {train_times_g4[i]:.3f}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bed0ad",
   "metadata": {},
   "source": [
    "## Batch Augmentation, Cutout Regularization \n",
    "### Q4.1\n",
    "**Cutout** is a regularization technique for convolutional neural networks where we essentially generate more training samples by creating versions of existing training input samples by removing a **contiguous sections**, thereby improving the generalization of the model by forcing it to focus more on generic minor features rather than local and specific major features of an image.\n",
    "\n",
    "#### Advantages of Cutout over Simple Dropout\n",
    "Cutout improves upon simple dropout due to the fact that the image is *augmented* (random section is removed) at the input stage and the subsequent feature maps in the deeper layers **also** do not contain the removed section. By contrast, simple dropout randomly removes features from every layer, creating the possibility of features removed in one layer to be present in another layer, thereby creating noisy representations of the input image. This *noise* **isn't generated** with cutout as the removed features remain consistent throughout the network, thereby creating a better (noise-free) augmented representation of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "543cff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = transF.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        \n",
    "class Cutout(object):\n",
    "    \"\"\"\n",
    "    Randomly mask out one or more patches from an image.\n",
    "    taken from https://github.com/uoguelph-mlrg/Cutout\n",
    "    Args:\n",
    "        holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, holes, length):\n",
    "        self.holes = holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4051676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7580bfb2",
   "metadata": {},
   "source": [
    "#### Original Image vs After Random Cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d50a714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a601e1ddf0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, _ = next(iter(trainloader))\n",
    "img = Cutout(1, 16)(images[0])\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "axes[0].imshow(images[0].permute(1, 2, 0))\n",
    "axes[1].imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5fa96",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b41b5e7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet20\n",
      "Total number of params 269722\n",
      "Total layers 20\n",
      "\n",
      "resnet32\n",
      "Total number of params 464154\n",
      "Total layers 32\n",
      "\n",
      "resnet44\n",
      "Total number of params 658586\n",
      "Total layers 44\n",
      "\n",
      "resnet56\n",
      "Total number of params 853018\n",
      "Total layers 56\n",
      "\n",
      "resnet110\n",
      "Total number of params 1727962\n",
      "Total layers 110\n",
      "\n",
      "resnet1202\n",
      "Total number of params 19421274\n",
      "Total layers 1202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "# We define all the classes and function regarding the ResNet architecture in this code cell\n",
    "__all__ = [\"resnet20\", \"resnet32\", \"resnet44\", \"resnet56\", \"resnet110\", \"resnet1202\"]\n",
    " \n",
    "def _weights_init(m):\n",
    "    \"\"\"\n",
    "        Initialization of CNN weights\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    \"\"\"\n",
    "      Identity mapping between ResNet blocks with diffrenet size feature map\n",
    "    \"\"\"\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "# A basic block as shown in Fig.3 (right) in the paper consists of two convolutional blocks, each followed by a Bach-Norm layer. \n",
    "# Every basic block is shortcuted in ResNet architecture to construct f(x)+x module. \n",
    "# Expansion for option 'A' in the paper is equal to identity with extra zero entries padded\n",
    "# for increasing dimensions between layers with different feature map size. This option introduces no extra parameter. \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 experiment, ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                     nn.BatchNorm2d(self.expansion * planes)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# Stack of 3 times 2*n (n is the number of basic blocks) layers are used for making the ResNet model, \n",
    "# where each 2n layers have feature maps of size {16,32,64}, respectively. \n",
    "# The subsampling is performed by convolutions with a stride of 2.\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def resnet20():\n",
    "    return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "\n",
    "def resnet32():\n",
    "    return ResNet(BasicBlock, [5, 5, 5])\n",
    "\n",
    "\n",
    "def resnet44():\n",
    "    return ResNet(BasicBlock, [7, 7, 7])\n",
    "\n",
    "\n",
    "def resnet56():\n",
    "    return ResNet(BasicBlock, [9, 9, 9])\n",
    "\n",
    "\n",
    "def resnet110():\n",
    "    return ResNet(BasicBlock, [18, 18, 18])\n",
    "\n",
    "\n",
    "def resnet1202():\n",
    "    return ResNet(BasicBlock, [200, 200, 200])\n",
    "\n",
    "\n",
    "def test(net):\n",
    "    total_params = 0\n",
    "\n",
    "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
    "        total_params += np.prod(x.data.numpy().shape)\n",
    "    print(\"Total number of params\", total_params)\n",
    "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for net_name in __all__:\n",
    "        if net_name.startswith('resnet'):\n",
    "            print(net_name)\n",
    "            test(globals()[net_name]())\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e52ec6",
   "metadata": {},
   "source": [
    "### Hyperparameter Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4912e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNetArgs:\n",
    "   \"\"\"\n",
    "    Passing the hyperparameters to the model\n",
    "   \"\"\"\n",
    "   def __init__(self, arch='resnet20' ,epochs=200, start_epoch=0, batch_size=128, lr=0.1, momentum=0.9, weight_decay=1e-4, print_freq=55,\n",
    "                 evaluate=0, pretrained=0, half=0, save_dir='save_temp', save_every=10):\n",
    "        self.save_every = save_every #Saves checkpoints at every specified number of epochs\n",
    "        self.save_dir = save_dir #The directory used to save the trained models\n",
    "        self.half = half #use half-precision(16-bit)\n",
    "        self.evaluate = evaluate #evaluate model on the validation set\n",
    "        self.pretrained = pretrained #evaluate the pretrained model on the validation set\n",
    "        self.print_freq = print_freq #print frequency \n",
    "        self.weight_decay = weight_decay\n",
    "        self.momentum = momentum \n",
    "        self.lr = lr #Learning rate\n",
    "        self.batch_size = batch_size \n",
    "        self.start_epoch = start_epoch\n",
    "        self.epochs = epochs\n",
    "        self.arch = arch #ResNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a44e13",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcec388a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "        BasicBlock-7           [-1, 16, 32, 32]               0\n",
      "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
      "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-12           [-1, 16, 32, 32]               0\n",
      "           Conv2d-13           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
      "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
      "           Conv2d-20           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-21           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-22           [-1, 16, 32, 32]               0\n",
      "           Conv2d-23           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-24           [-1, 16, 32, 32]              32\n",
      "           Conv2d-25           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-26           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-27           [-1, 16, 32, 32]               0\n",
      "           Conv2d-28           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-29           [-1, 16, 32, 32]              32\n",
      "           Conv2d-30           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-31           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-32           [-1, 16, 32, 32]               0\n",
      "           Conv2d-33           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-34           [-1, 16, 32, 32]              32\n",
      "           Conv2d-35           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-36           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-37           [-1, 16, 32, 32]               0\n",
      "           Conv2d-38           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-39           [-1, 32, 16, 16]              64\n",
      "           Conv2d-40           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-41           [-1, 32, 16, 16]              64\n",
      "      LambdaLayer-42           [-1, 32, 16, 16]               0\n",
      "       BasicBlock-43           [-1, 32, 16, 16]               0\n",
      "           Conv2d-44           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-45           [-1, 32, 16, 16]              64\n",
      "           Conv2d-46           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-47           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-48           [-1, 32, 16, 16]               0\n",
      "           Conv2d-49           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-50           [-1, 32, 16, 16]              64\n",
      "           Conv2d-51           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-52           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-53           [-1, 32, 16, 16]               0\n",
      "           Conv2d-54           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-55           [-1, 32, 16, 16]              64\n",
      "           Conv2d-56           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-57           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-58           [-1, 32, 16, 16]               0\n",
      "           Conv2d-59           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-60           [-1, 32, 16, 16]              64\n",
      "           Conv2d-61           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-62           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-63           [-1, 32, 16, 16]               0\n",
      "           Conv2d-64           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-65           [-1, 32, 16, 16]              64\n",
      "           Conv2d-66           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-67           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-68           [-1, 32, 16, 16]               0\n",
      "           Conv2d-69           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-70           [-1, 32, 16, 16]              64\n",
      "           Conv2d-71           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-72           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-73           [-1, 32, 16, 16]               0\n",
      "           Conv2d-74             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-75             [-1, 64, 8, 8]             128\n",
      "           Conv2d-76             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-77             [-1, 64, 8, 8]             128\n",
      "      LambdaLayer-78             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-79             [-1, 64, 8, 8]               0\n",
      "           Conv2d-80             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-81             [-1, 64, 8, 8]             128\n",
      "           Conv2d-82             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-83             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-84             [-1, 64, 8, 8]               0\n",
      "           Conv2d-85             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-86             [-1, 64, 8, 8]             128\n",
      "           Conv2d-87             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-88             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-89             [-1, 64, 8, 8]               0\n",
      "           Conv2d-90             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-91             [-1, 64, 8, 8]             128\n",
      "           Conv2d-92             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-93             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-94             [-1, 64, 8, 8]               0\n",
      "           Conv2d-95             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-96             [-1, 64, 8, 8]             128\n",
      "           Conv2d-97             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-98             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-99             [-1, 64, 8, 8]               0\n",
      "          Conv2d-100             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-101             [-1, 64, 8, 8]             128\n",
      "          Conv2d-102             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-103             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-104             [-1, 64, 8, 8]               0\n",
      "          Conv2d-105             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-106             [-1, 64, 8, 8]             128\n",
      "          Conv2d-107             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-108             [-1, 64, 8, 8]             128\n",
      "      BasicBlock-109             [-1, 64, 8, 8]               0\n",
      "          Linear-110                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 658,586\n",
      "Trainable params: 658,586\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 8.00\n",
      "Params size (MB): 2.51\n",
      "Estimated Total Size (MB): 10.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "args=MyResNetArgs('resnet44',pretrained=0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = resnet44().to(device)\n",
    "summary(model, (3,32,32))\n",
    "best_prec1 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f36c79",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0d6a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    \"\"\"\n",
    "    Save the training model\n",
    "    \"\"\"\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    print_freq = 50\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    losses = []\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        target = target.cuda()\n",
    "        input_var = input.cuda()\n",
    "        target_var = target\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.item()\n",
    "        losses.append(loss)\n",
    "    \n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time:.3f}\\t'\n",
    "                  'Loss {loss:.4f}\\t'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=time.time() - end, loss=loss))\n",
    "        \n",
    "        # measure elapsed time\n",
    "        end = time.time()\n",
    "    \n",
    "    return sum(losses) / len(losses)\n",
    "\n",
    "\n",
    "def accuracy(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inp, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            input_var = inp.cuda()\n",
    "            target_var = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            _, prediction = torch.max(output.data, 1)\n",
    "            \n",
    "            correct += (prediction == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    return (100 * correct) // total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5375a",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30abd670",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "batch_size = 64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=True)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=128, shuffle=False,\n",
    "        num_workers=0, pin_memory=True)\n",
    "\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239672d0",
   "metadata": {},
   "source": [
    "### Q4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b93e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [0][0/782]\tTime 0.191\tLoss 3.3071\t\n",
      "Epoch: [0][50/782]\tTime 0.046\tLoss 2.3304\t\n",
      "Epoch: [0][100/782]\tTime 0.048\tLoss 2.1834\t\n",
      "Epoch: [0][150/782]\tTime 0.046\tLoss 1.9114\t\n",
      "Epoch: [0][200/782]\tTime 0.046\tLoss 1.8502\t\n",
      "Epoch: [0][250/782]\tTime 0.046\tLoss 1.8742\t\n",
      "Epoch: [0][300/782]\tTime 0.048\tLoss 1.6938\t\n",
      "Epoch: [0][350/782]\tTime 0.046\tLoss 1.6526\t\n",
      "Epoch: [0][400/782]\tTime 0.048\tLoss 1.8549\t\n",
      "Epoch: [0][450/782]\tTime 0.048\tLoss 1.7043\t\n",
      "Epoch: [0][500/782]\tTime 0.048\tLoss 1.6448\t\n",
      "Epoch: [0][550/782]\tTime 0.048\tLoss 1.7169\t\n",
      "Epoch: [0][600/782]\tTime 0.048\tLoss 1.7134\t\n",
      "Epoch: [0][650/782]\tTime 0.046\tLoss 1.6415\t\n",
      "Epoch: [0][700/782]\tTime 0.048\tLoss 1.4030\t\n",
      "Epoch: [0][750/782]\tTime 0.048\tLoss 1.3787\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [1][0/782]\tTime 0.046\tLoss 1.7329\t\n",
      "Epoch: [1][50/782]\tTime 0.048\tLoss 1.3637\t\n",
      "Epoch: [1][100/782]\tTime 0.048\tLoss 1.1871\t\n",
      "Epoch: [1][150/782]\tTime 0.048\tLoss 1.3258\t\n",
      "Epoch: [1][200/782]\tTime 0.044\tLoss 1.3944\t\n",
      "Epoch: [1][250/782]\tTime 0.048\tLoss 1.4645\t\n",
      "Epoch: [1][300/782]\tTime 0.048\tLoss 1.2106\t\n",
      "Epoch: [1][350/782]\tTime 0.048\tLoss 1.2075\t\n",
      "Epoch: [1][400/782]\tTime 0.046\tLoss 1.2794\t\n",
      "Epoch: [1][450/782]\tTime 0.048\tLoss 1.0533\t\n",
      "Epoch: [1][500/782]\tTime 0.048\tLoss 1.0495\t\n",
      "Epoch: [1][550/782]\tTime 0.046\tLoss 0.9248\t\n",
      "Epoch: [1][600/782]\tTime 0.046\tLoss 1.2603\t\n",
      "Epoch: [1][650/782]\tTime 0.048\tLoss 0.9571\t\n",
      "Epoch: [1][700/782]\tTime 0.046\tLoss 1.0607\t\n",
      "Epoch: [1][750/782]\tTime 0.048\tLoss 1.1333\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [2][0/782]\tTime 0.050\tLoss 1.0507\t\n",
      "Epoch: [2][50/782]\tTime 0.048\tLoss 1.1449\t\n",
      "Epoch: [2][100/782]\tTime 0.048\tLoss 0.9313\t\n",
      "Epoch: [2][150/782]\tTime 0.048\tLoss 0.9384\t\n",
      "Epoch: [2][200/782]\tTime 0.048\tLoss 1.2347\t\n",
      "Epoch: [2][250/782]\tTime 0.050\tLoss 0.6687\t\n",
      "Epoch: [2][300/782]\tTime 0.048\tLoss 0.9169\t\n",
      "Epoch: [2][350/782]\tTime 0.048\tLoss 0.8947\t\n",
      "Epoch: [2][400/782]\tTime 0.046\tLoss 0.9119\t\n",
      "Epoch: [2][450/782]\tTime 0.050\tLoss 0.9614\t\n",
      "Epoch: [2][500/782]\tTime 0.048\tLoss 0.9606\t\n",
      "Epoch: [2][550/782]\tTime 0.046\tLoss 0.9182\t\n",
      "Epoch: [2][600/782]\tTime 0.048\tLoss 0.8235\t\n",
      "Epoch: [2][650/782]\tTime 0.048\tLoss 1.0272\t\n",
      "Epoch: [2][700/782]\tTime 0.046\tLoss 0.8151\t\n",
      "Epoch: [2][750/782]\tTime 0.046\tLoss 0.9020\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [3][0/782]\tTime 0.046\tLoss 0.9139\t\n",
      "Epoch: [3][50/782]\tTime 0.050\tLoss 0.8514\t\n",
      "Epoch: [3][100/782]\tTime 0.048\tLoss 0.8070\t\n",
      "Epoch: [3][150/782]\tTime 0.048\tLoss 0.7244\t\n",
      "Epoch: [3][200/782]\tTime 0.048\tLoss 0.5847\t\n",
      "Epoch: [3][250/782]\tTime 0.046\tLoss 0.6013\t\n",
      "Epoch: [3][300/782]\tTime 0.050\tLoss 0.6841\t\n",
      "Epoch: [3][350/782]\tTime 0.046\tLoss 0.7462\t\n",
      "Epoch: [3][400/782]\tTime 0.050\tLoss 0.7286\t\n",
      "Epoch: [3][450/782]\tTime 0.048\tLoss 0.5327\t\n",
      "Epoch: [3][500/782]\tTime 0.048\tLoss 1.0390\t\n",
      "Epoch: [3][550/782]\tTime 0.050\tLoss 0.8418\t\n",
      "Epoch: [3][600/782]\tTime 0.048\tLoss 0.7529\t\n",
      "Epoch: [3][650/782]\tTime 0.050\tLoss 0.8209\t\n",
      "Epoch: [3][700/782]\tTime 0.046\tLoss 0.7072\t\n",
      "Epoch: [3][750/782]\tTime 0.050\tLoss 0.8803\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [4][0/782]\tTime 0.046\tLoss 0.7448\t\n",
      "Epoch: [4][50/782]\tTime 0.050\tLoss 0.7573\t\n",
      "Epoch: [4][100/782]\tTime 0.048\tLoss 0.6382\t\n",
      "Epoch: [4][150/782]\tTime 0.048\tLoss 0.8502\t\n",
      "Epoch: [4][200/782]\tTime 0.050\tLoss 0.5503\t\n",
      "Epoch: [4][250/782]\tTime 0.048\tLoss 0.5042\t\n",
      "Epoch: [4][300/782]\tTime 0.048\tLoss 0.7556\t\n",
      "Epoch: [4][350/782]\tTime 0.048\tLoss 0.8003\t\n",
      "Epoch: [4][400/782]\tTime 0.048\tLoss 0.5024\t\n",
      "Epoch: [4][450/782]\tTime 0.046\tLoss 0.5093\t\n",
      "Epoch: [4][500/782]\tTime 0.048\tLoss 0.5685\t\n",
      "Epoch: [4][550/782]\tTime 0.050\tLoss 0.5599\t\n",
      "Epoch: [4][600/782]\tTime 0.048\tLoss 0.6057\t\n",
      "Epoch: [4][650/782]\tTime 0.048\tLoss 0.5545\t\n",
      "Epoch: [4][700/782]\tTime 0.048\tLoss 0.7392\t\n",
      "Epoch: [4][750/782]\tTime 0.048\tLoss 0.7539\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [5][0/782]\tTime 0.048\tLoss 0.4548\t\n",
      "Epoch: [5][50/782]\tTime 0.048\tLoss 0.6716\t\n",
      "Epoch: [5][100/782]\tTime 0.044\tLoss 0.8375\t\n",
      "Epoch: [5][150/782]\tTime 0.048\tLoss 0.8036\t\n",
      "Epoch: [5][200/782]\tTime 0.050\tLoss 0.4435\t\n",
      "Epoch: [5][250/782]\tTime 0.050\tLoss 0.6215\t\n",
      "Epoch: [5][300/782]\tTime 0.048\tLoss 0.8279\t\n",
      "Epoch: [5][350/782]\tTime 0.048\tLoss 0.6740\t\n",
      "Epoch: [5][400/782]\tTime 0.046\tLoss 0.5200\t\n",
      "Epoch: [5][450/782]\tTime 0.048\tLoss 0.5487\t\n",
      "Epoch: [5][500/782]\tTime 0.046\tLoss 0.5684\t\n",
      "Epoch: [5][550/782]\tTime 0.048\tLoss 0.7047\t\n",
      "Epoch: [5][600/782]\tTime 0.048\tLoss 0.4819\t\n",
      "Epoch: [5][650/782]\tTime 0.048\tLoss 0.5888\t\n",
      "Epoch: [5][700/782]\tTime 0.046\tLoss 0.7837\t\n",
      "Epoch: [5][750/782]\tTime 0.048\tLoss 0.5570\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [6][0/782]\tTime 0.050\tLoss 0.4774\t\n",
      "Epoch: [6][50/782]\tTime 0.046\tLoss 0.4275\t\n",
      "Epoch: [6][100/782]\tTime 0.048\tLoss 0.4862\t\n",
      "Epoch: [6][150/782]\tTime 0.048\tLoss 0.7041\t\n",
      "Epoch: [6][200/782]\tTime 0.046\tLoss 0.4097\t\n",
      "Epoch: [6][250/782]\tTime 0.044\tLoss 0.4388\t\n",
      "Epoch: [6][300/782]\tTime 0.048\tLoss 0.5866\t\n",
      "Epoch: [6][350/782]\tTime 0.048\tLoss 0.7697\t\n",
      "Epoch: [6][400/782]\tTime 0.050\tLoss 0.5960\t\n",
      "Epoch: [6][450/782]\tTime 0.050\tLoss 0.4881\t\n",
      "Epoch: [6][500/782]\tTime 0.048\tLoss 0.5628\t\n",
      "Epoch: [6][550/782]\tTime 0.048\tLoss 0.4814\t\n",
      "Epoch: [6][600/782]\tTime 0.050\tLoss 0.6779\t\n",
      "Epoch: [6][650/782]\tTime 0.050\tLoss 0.3618\t\n",
      "Epoch: [6][700/782]\tTime 0.048\tLoss 0.5542\t\n",
      "Epoch: [6][750/782]\tTime 0.050\tLoss 0.4823\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [7][0/782]\tTime 0.046\tLoss 0.5423\t\n",
      "Epoch: [7][50/782]\tTime 0.048\tLoss 0.5498\t\n",
      "Epoch: [7][100/782]\tTime 0.048\tLoss 0.7169\t\n",
      "Epoch: [7][150/782]\tTime 0.048\tLoss 0.5380\t\n",
      "Epoch: [7][200/782]\tTime 0.047\tLoss 0.4625\t\n",
      "Epoch: [7][250/782]\tTime 0.046\tLoss 0.4809\t\n",
      "Epoch: [7][300/782]\tTime 0.046\tLoss 0.6081\t\n",
      "Epoch: [7][350/782]\tTime 0.048\tLoss 0.5610\t\n",
      "Epoch: [7][400/782]\tTime 0.050\tLoss 0.5382\t\n",
      "Epoch: [7][450/782]\tTime 0.048\tLoss 0.4013\t\n",
      "Epoch: [7][500/782]\tTime 0.046\tLoss 0.6486\t\n",
      "Epoch: [7][550/782]\tTime 0.048\tLoss 0.3802\t\n",
      "Epoch: [7][600/782]\tTime 0.048\tLoss 0.6103\t\n",
      "Epoch: [7][650/782]\tTime 0.050\tLoss 0.2651\t\n",
      "Epoch: [7][700/782]\tTime 0.050\tLoss 0.5328\t\n",
      "Epoch: [7][750/782]\tTime 0.044\tLoss 0.7386\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [8][0/782]\tTime 0.050\tLoss 0.5137\t\n",
      "Epoch: [8][50/782]\tTime 0.046\tLoss 0.5653\t\n",
      "Epoch: [8][100/782]\tTime 0.046\tLoss 0.6797\t\n",
      "Epoch: [8][150/782]\tTime 0.048\tLoss 0.5226\t\n",
      "Epoch: [8][200/782]\tTime 0.048\tLoss 0.3426\t\n",
      "Epoch: [8][250/782]\tTime 0.048\tLoss 0.5309\t\n",
      "Epoch: [8][300/782]\tTime 0.048\tLoss 0.4216\t\n",
      "Epoch: [8][350/782]\tTime 0.048\tLoss 0.4474\t\n",
      "Epoch: [8][400/782]\tTime 0.048\tLoss 0.3887\t\n",
      "Epoch: [8][450/782]\tTime 0.048\tLoss 0.3587\t\n",
      "Epoch: [8][500/782]\tTime 0.048\tLoss 0.5635\t\n",
      "Epoch: [8][550/782]\tTime 0.046\tLoss 0.4039\t\n",
      "Epoch: [8][600/782]\tTime 0.048\tLoss 0.5643\t\n",
      "Epoch: [8][650/782]\tTime 0.048\tLoss 0.5102\t\n",
      "Epoch: [8][700/782]\tTime 0.046\tLoss 0.3797\t\n",
      "Epoch: [8][750/782]\tTime 0.048\tLoss 0.7054\t\n",
      "Training Resnet-44 model\n",
      "current lr 1.00000e-01\n",
      "Epoch: [9][0/782]\tTime 0.046\tLoss 0.4311\t\n",
      "Epoch: [9][50/782]\tTime 0.048\tLoss 0.4898\t\n",
      "Epoch: [9][100/782]\tTime 0.048\tLoss 0.4965\t\n",
      "Epoch: [9][150/782]\tTime 0.048\tLoss 0.3647\t\n",
      "Epoch: [9][200/782]\tTime 0.048\tLoss 0.5154\t\n",
      "Epoch: [9][250/782]\tTime 0.048\tLoss 0.5782\t\n",
      "Epoch: [9][300/782]\tTime 0.049\tLoss 0.5552\t\n",
      "Epoch: [9][350/782]\tTime 0.051\tLoss 0.3031\t\n",
      "Epoch: [9][400/782]\tTime 0.050\tLoss 0.3723\t\n",
      "Epoch: [9][450/782]\tTime 0.048\tLoss 0.6165\t\n",
      "Epoch: [9][500/782]\tTime 0.050\tLoss 0.3759\t\n",
      "Epoch: [9][550/782]\tTime 0.050\tLoss 0.3446\t\n",
      "Epoch: [9][600/782]\tTime 0.048\tLoss 0.6127\t\n",
      "Epoch: [9][650/782]\tTime 0.050\tLoss 0.4958\t\n",
      "Epoch: [9][700/782]\tTime 0.048\tLoss 0.5951\t\n",
      "Epoch: [9][750/782]\tTime 0.046\tLoss 0.4332\t\n"
     ]
    }
   ],
   "source": [
    "def training_validation_error(trainloader, valloader, epochs, accuracy_threshold = None):\n",
    "    lr, momentum, weight_decay = 0.1, 0.9, 1e-4\n",
    "\n",
    "    model = resnet44()\n",
    "    model.cuda()\n",
    "\n",
    "\n",
    "    # define loss function (criterion) and pptimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 60, 80])\n",
    "    val_error = []\n",
    "    epochs_elapsed, start_time = 0, datetime.now()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epochs_elapsed += 1\n",
    "        # train for one epoch\n",
    "        print('Training Resnet-44 model')\n",
    "        print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
    "        train(trainloader, model, criterion, optimizer, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # evaluate on validation set\n",
    "        epoch_accuracy = accuracy(valloader, model, criterion)\n",
    "        val_error.append(100. - epoch_accuracy)\n",
    "        \n",
    "        if accuracy_threshold is not None and epoch_accuracy >= accuracy_threshold:\n",
    "            break\n",
    "        \n",
    "    return val_error, epochs_elapsed, datetime.now() - start_time\n",
    "\n",
    "epochs = 10\n",
    "base_error, _, _ = training_validation_error(trainloader, valloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f14e06cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), base_error)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Resnet-44 | Valdation Error vs Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1351a881",
   "metadata": {},
   "source": [
    "### Q4.3\n",
    "#### Load Data with Cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccf1bbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(924.967830882353, 0.5, 'Time(s)')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "n_holes = [2,4,8,16,32]\n",
    "epochs_till_94, runtime_till_94 = [],  []\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, figsize=(20, 5))\n",
    "\n",
    "for holes in n_holes:\n",
    "    # Base training set with no augmentations\n",
    "    transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomCrop(32, 4),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "    augmented_trainset = [torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)]\n",
    "    \n",
    "    # Add new augmented data to training set\n",
    "    for _ in range(holes):\n",
    "        augmentations = transforms.Compose([\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomCrop(32, 4),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,\n",
    "                    Cutout(holes, 16)\n",
    "                ])\n",
    "        augmented_trainset.append(torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform))\n",
    "    \n",
    "    # Merge all variations of the dataset into one\n",
    "    trainset = ConcatDataset(augmented_trainset)\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "            batch_size=batch_size, shuffle=True,\n",
    "            num_workers=0, pin_memory=True)\n",
    "\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "            torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])),\n",
    "            batch_size=128, shuffle=False,\n",
    "            num_workers=0, pin_memory=True)\n",
    "    \n",
    "    cutout_error, epochs_elapsed, runtime = training_validation_error(trainloader, valloader, epochs, accuracy_threshold = 94)\n",
    "    epochs_till_94.append(epochs_elapsed)\n",
    "    runtime_till_94.append(runtime.total_seconds())\n",
    "    \n",
    "#     plt.plot(range(epochs), training_losses, label=\"Training\")\n",
    "    axes[0].plot(range(epochs_elapsed), cutout_error, label=f\"M = {holes}\")\n",
    "\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Error\")\n",
    "axes[0].set_title(\"Resnet-44 | Error vs Epochs\")\n",
    "axes[0].legend(loc=\"best\")\n",
    "\n",
    "axes[1].plot(n_holes, epochs_till_94)\n",
    "axes[1].set_xlabel(r\"$M$\")\n",
    "axes[1].set_ylabel(\"Epochs\")\n",
    "axes[1].set_title(\"Epochs taken to reach 94% accuracy\")\n",
    "\n",
    "axes[2].set_title(\"Time take to reach 94% accuracy\")\n",
    "axes[2].plot(n_holes, runtime_till_94)\n",
    "axes[2].set_xlabel(r\"$M$\")\n",
    "axes[2].set_ylabel(\"Time(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "faeaa776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9796370875"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(runtime_till_94) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dcf1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.notification.emailer import *\n",
    "\n",
    "msg = message.email(text=\"Training Done.\", subject=\"IDLS Lab Notebook Notification\")\n",
    "mail_io.send(msg, server=\"smtp.gmail.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
